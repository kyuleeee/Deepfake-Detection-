{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c195005d",
   "metadata": {},
   "source": [
    "## 1. TRY 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5cd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q face-recognition==1.3.0 albumentations==1.3.0 decord==0.6.0 timm==0.6.5 opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from models.pred_func import load_genconvit, pred_vid, face_rec, preprocess_frame, is_video, extract_frames\n",
    "from models.config import load_config\n",
    "from typing import List, Dict, Union\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "def save_results_to_csv(\n",
    "    results: List[Dict[str, Union[str, int, List[float]]]],\n",
    "    filepath: str,\n",
    "    for_submit=False,\n",
    ") -> None:\n",
    "    \"\"\"Save results to CSV with sorted filenames\"\"\"\n",
    "    sorted_results = sorted(results, key=lambda x: x['name'])\n",
    "    \n",
    "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        row = w.writerow\n",
    "        if for_submit:\n",
    "            row((\"filename\", \"label\"))\n",
    "            for r in sorted_results:\n",
    "                row((r['name'], r['pred']))\n",
    "        else:\n",
    "            row((\"name\", \"pred\", \"pred_proba\"))\n",
    "            for r in sorted_results:\n",
    "                row((r[\"name\"], r[\"pred\"], r[\"pred_proba\"]))\n",
    "\n",
    "\n",
    "def get_files_paths(main_path: str, exs: List[str]) -> List[str]:\n",
    "    \"\"\"Collect all files with specified extensions\"\"\"\n",
    "    exs = {(\".\" + ext.lstrip(\".\")).lower() for ext in exs}\n",
    "    results = []\n",
    "    \n",
    "    for root, _, files in os.walk(main_path):\n",
    "        for fname in files:\n",
    "            abs_path = os.path.abspath(os.path.join(root, fname))\n",
    "            _, ext = os.path.splitext(fname)\n",
    "            if ext.lower() in exs:\n",
    "                results.append(abs_path)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_laplacian_variance(frames):\n",
    "    \"\"\"Calculate Laplacian variance (sharpness/detail measure)\"\"\"\n",
    "    if len(frames) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    laplacian_vars = []\n",
    "    for i in range(len(frames)):\n",
    "        frame = frames[i]\n",
    "        if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = frame\n",
    "        \n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        variance = laplacian.var()\n",
    "        laplacian_vars.append(variance)\n",
    "    \n",
    "    return np.mean(laplacian_vars)\n",
    "\n",
    "def check_frequency_artifacts(image):\n",
    "    \"\"\"Check for deepfake artifacts in frequency domain\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    f_transform = np.fft.fft2(image)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "    magnitude_spectrum = np.abs(f_shift)\n",
    "    \n",
    "    h, w = magnitude_spectrum.shape\n",
    "    center_h, center_w = h // 2, w // 2\n",
    "    \n",
    "    high_freq_region = magnitude_spectrum.copy()\n",
    "    mask_radius = min(h, w) // 4\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    mask = (x - center_w)**2 + (y - center_h)**2 <= mask_radius**2\n",
    "    high_freq_region[mask] = 0\n",
    "    \n",
    "    total_energy = np.sum(magnitude_spectrum)\n",
    "    high_freq_energy = np.sum(high_freq_region)\n",
    "    high_freq_ratio = high_freq_energy / (total_energy + 1e-10)\n",
    "    \n",
    "    return high_freq_ratio\n",
    "\n",
    "\n",
    "def check_face_boundary_artifacts(image):\n",
    "    \"\"\"Check for artifacts around face boundaries\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    border_width = int(min(h, w) * 0.1)\n",
    "    \n",
    "    top_border = image[:border_width, :]\n",
    "    bottom_border = image[-border_width:, :]\n",
    "    left_border = image[:, :border_width]\n",
    "    right_border = image[:, -border_width:]\n",
    "    \n",
    "    border_regions = [top_border, bottom_border, left_border, right_border]\n",
    "    border_stds = [np.std(region) for region in border_regions]\n",
    "    avg_border_std = np.mean(border_stds)\n",
    "    \n",
    "    center_region = image[border_width:-border_width, border_width:-border_width]\n",
    "    center_std = np.std(center_region)\n",
    "    \n",
    "    boundary_anomaly = abs(avg_border_std - center_std) / (center_std + 1e-10)\n",
    "    return boundary_anomaly\n",
    "\n",
    "\n",
    "def check_color_consistency(image):\n",
    "    \"\"\"Check color consistency across RGB channels\"\"\"\n",
    "    r_mean = np.mean(image[:,:,0])\n",
    "    g_mean = np.mean(image[:,:,1])\n",
    "    b_mean = np.mean(image[:,:,2])\n",
    "    \n",
    "    channel_imbalance = np.std([r_mean, g_mean, b_mean]) / (np.mean([r_mean, g_mean, b_mean]) + 1e-10)\n",
    "    return channel_imbalance\n",
    "\n",
    "\n",
    "def perform_secondary_checks(image, laplacian_var):\n",
    "    \"\"\"Perform secondary verification for sharp images\"\"\"\n",
    "    freq_artifact = check_frequency_artifacts(image)\n",
    "    boundary_artifact = check_face_boundary_artifacts(image)\n",
    "    color_inconsistency = check_color_consistency(image)\n",
    "    \n",
    "    freq_score = 0.0\n",
    "    if freq_artifact < 0.01 or freq_artifact > 0.12:\n",
    "        freq_score = min(abs(freq_artifact - 0.05) / 0.05, 1.0)\n",
    "    \n",
    "    boundary_score = min(boundary_artifact / 1.0, 1.0)\n",
    "    color_score = min(color_inconsistency / 0.5, 1.0)\n",
    "    \n",
    "    suspicion_score = (\n",
    "        0.5 * freq_score +\n",
    "        0.2 * boundary_score +\n",
    "        0.3 * color_score\n",
    "    )\n",
    "    \n",
    "    return suspicion_score\n",
    "\n",
    "# ===== CPU WORKER FUNCTION (runs in parallel) =====\n",
    "def process_single_file(args):\n",
    "    \"\"\"Worker function: CPU tasks (face detection, Laplacian)\"\"\"\n",
    "    file_path, num_frames, consecutive = args\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    try:\n",
    "        if is_video(file_path):\n",
    "            # Extract raw frames\n",
    "            raw_frames = extract_frames(file_path, num_frames, consecutive=consecutive)\n",
    "            # Detect faces\n",
    "            face_crops, count = face_rec(raw_frames)\n",
    "            \n",
    "            if count > 0:\n",
    "                # Calculate Laplacian on face regions\n",
    "                laplacian_var = calculate_laplacian_variance(face_crops[:count])\n",
    "                return (filename, face_crops[:count], laplacian_var, True, None)  # is_video=True\n",
    "            else:\n",
    "                return (filename, None, 0.0, True, None)\n",
    "        else:\n",
    "            # Load image\n",
    "            im = Image.open(file_path).convert('RGB')\n",
    "            arr = np.asarray(im)\n",
    "            \n",
    "            # Detect face\n",
    "            face, count = face_rec([arr])\n",
    "            \n",
    "            if count > 0:\n",
    "                laplacian_var = calculate_laplacian_variance(face[:count])\n",
    "                raw_image = face[0]\n",
    "                return (filename, face[:count], laplacian_var, False, raw_image)  # is_video=False\n",
    "            else:\n",
    "                return (filename, None, 0.0, False, None)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (filename, None, 0.0, None, str(e))\n",
    "\n",
    "\n",
    "def extract_features(model, df, fp16_mode=False):\n",
    "    \"\"\"Extract features and calculate statistics\"\"\"\n",
    "    if df.shape[0] == 0:\n",
    "        return None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if fp16_mode:\n",
    "            df = df.half()\n",
    "        features = model.extract_features(df)\n",
    "        features_np = features.cpu().numpy()\n",
    "        \n",
    "        feat_stats = {\n",
    "            'mean': features_np.mean(axis=0),\n",
    "            'std': features_np.std(axis=0).mean(),\n",
    "            'num_frames': features_np.shape[0]\n",
    "        }\n",
    "        \n",
    "        if features_np.shape[0] > 1:\n",
    "            frame_diffs = np.diff(features_np, axis=0)\n",
    "            feat_stats['temporal_variance'] = np.mean(np.var(frame_diffs, axis=0))\n",
    "            \n",
    "            per_frame_std = np.std(features_np, axis=1).mean()\n",
    "            feat_stats['per_frame_std'] = per_frame_std\n",
    "            \n",
    "            frame_distances = np.linalg.norm(features_np - features_np.mean(axis=0), axis=1)\n",
    "            threshold = np.median(frame_distances) + 2 * np.std(frame_distances)\n",
    "            outlier_ratio = np.sum(frame_distances > threshold) / features_np.shape[0]\n",
    "            feat_stats['outlier_ratio'] = outlier_ratio\n",
    "        else:\n",
    "            feat_stats['temporal_variance'] = 0.0\n",
    "            feat_stats['per_frame_std'] = np.std(features_np)\n",
    "            feat_stats['outlier_ratio'] = 0.0\n",
    "        \n",
    "        return feat_stats\n",
    "\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "DATA_PATH = \"data\"  # Change this to your test data path\n",
    "NUM_FRAMES = 25\n",
    "FP16_MODE = False\n",
    "CONSECUTIVE_FRAMES = True\n",
    "NUM_WORKERS = None  # None = auto-detect (CPU count - 1)\n",
    "\n",
    "# Model setup\n",
    "net = 'genconvit'\n",
    "ed_weight = 'genconvit_ed_inference'\n",
    "vae_weight = 'genconvit_vae_inference'\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "model = load_genconvit(config, net, ed_weight, vae_weight, FP16_MODE)\n",
    "print(f\"✓ Loaded {net} network\")\n",
    "\n",
    "# Collect files\n",
    "all_files = get_files_paths(DATA_PATH, exs=['png', 'jpg', 'jpeg', 'mp4'])\n",
    "print(f\"✓ Found {len(all_files)} files\")\n",
    "\n",
    "# Setup multiprocessing\n",
    "num_workers = NUM_WORKERS if NUM_WORKERS else min(max(1, multiprocessing.cpu_count() - 1), 8)\n",
    "print(f\"✓ Using {num_workers} worker processes\")\n",
    "print(f\"✓ Frame extraction: {'consecutive' if CONSECUTIVE_FRAMES else 'evenly spaced'}\\n\")\n",
    "\n",
    "# Prepare worker arguments\n",
    "worker_args = [(file_path, NUM_FRAMES, CONSECUTIVE_FRAMES) for file_path in all_files]\n",
    "\n",
    "\n",
    "# ===== MAIN PROCESSING LOOP =====\n",
    "results = []\n",
    "\n",
    "print(\"Start Evaluating...\")\n",
    "with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "    with tqdm(total=len(all_files), desc=\"Processing files\") as pbar:\n",
    "        for result in pool.imap_unordered(process_single_file, worker_args):\n",
    "            filename, face_crops, laplacian_var, is_video_file, raw_image = result\n",
    "            \n",
    "            # Check for errors\n",
    "            if isinstance(raw_image, str):  # Error message\n",
    "                print(f\"Error processing {filename}: {raw_image}\")\n",
    "                results.append({\n",
    "                    \"name\": filename,\n",
    "                    \"pred\": 0,\n",
    "                    \"pred_proba\": [0.5, 0.5]\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            # No face detected\n",
    "            if face_crops is None:\n",
    "                results.append({\n",
    "                    \"name\": filename,\n",
    "                    \"pred\": 0,\n",
    "                    \"pred_proba\": [0.5, 0.5]\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            # ===== GPU INFERENCE =====\n",
    "            df = preprocess_frame(face_crops)\n",
    "            if FP16_MODE and df.shape[0] > 0:\n",
    "                df = df.half()\n",
    "            \n",
    "            real_proba, fake_proba = (\n",
    "                pred_vid(df, model)\n",
    "                if df.shape[0] > 0\n",
    "                else (0.0, 0.5)\n",
    "            )\n",
    "            \n",
    "            feat_stats = extract_features(model, df, FP16_MODE)\n",
    "            if feat_stats:\n",
    "                feat_stats['laplacian_var'] = laplacian_var\n",
    "            \n",
    "\n",
    "            \n",
    "            # ===== MULTI-LAYER DETECTION =====\n",
    "            temporal_var = feat_stats['temporal_variance'] if feat_stats else 0.0\n",
    "            force_fake = False\n",
    "            \n",
    "            HIGH_LAPLACIAN = 180\n",
    "            HIGH_TEMPORAL_VAR = 0.02\n",
    "            EXTREME_TEMPORAL_VAR = 0.04\n",
    "            \n",
    "            if is_video_file:\n",
    "                # VEO-style: sharp + jerky\n",
    "                if laplacian_var > HIGH_LAPLACIAN and temporal_var > HIGH_TEMPORAL_VAR:\n",
    "                    veo_boost = 1.0 + (temporal_var * 15)\n",
    "                    fake_proba = min(1.0, fake_proba * veo_boost)\n",
    "                    if temporal_var > EXTREME_TEMPORAL_VAR:\n",
    "                        force_fake = True\n",
    "                \n",
    "                # SORA-style: smooth + blurry\n",
    "                elif laplacian_var < HIGH_LAPLACIAN and temporal_var < HIGH_TEMPORAL_VAR:\n",
    "                    if laplacian_var < 50:\n",
    "                        fake_proba = min(1.0, fake_proba * 1.3)\n",
    "                        if laplacian_var < 30:\n",
    "                            force_fake = True\n",
    "                \n",
    "                # Low-quality: blurry + jerky\n",
    "                elif laplacian_var < HIGH_LAPLACIAN and temporal_var > HIGH_TEMPORAL_VAR:\n",
    "                    fake_proba = min(1.0, fake_proba * 1.5)\n",
    "                    force_fake = True\n",
    "                \n",
    "                # Spatial anomaly\n",
    "                if feat_stats and feat_stats.get('outlier_ratio', 0) > 0.3:\n",
    "                    force_fake = True\n",
    "            \n",
    "            else:\n",
    "                # Image detection\n",
    "                SHARPNESS_THRESHOLD = 180.0\n",
    "                SUSPICION_THRESHOLD = 0.60\n",
    "                \n",
    "                # if laplacian_var > 200:\n",
    "                #     fake_proba = min(1.0, fake_proba * 1.3)\n",
    "                #     if laplacian_var > 300:\n",
    "                #         force_fake = True\n",
    "                # elif laplacian_var < 40:\n",
    "                #     fake_proba = min(1.0, fake_proba * 1.2)\n",
    "                #     if laplacian_var < 20:\n",
    "                #         force_fake = True\n",
    "                \n",
    "                # if feat_stats and feat_stats.get('per_frame_std', 0) > 8.0:\n",
    "                #     force_fake = True\n",
    "                \n",
    "                # Secondary check\n",
    "                if laplacian_var > SHARPNESS_THRESHOLD and fake_proba < real_proba and raw_image is not None:\n",
    "                    suspicion_score = perform_secondary_checks(raw_image, laplacian_var)\n",
    "                    if suspicion_score > SUSPICION_THRESHOLD:\n",
    "                        force_fake = True\n",
    "            \n",
    "            y = 1 if (force_fake or fake_proba >= real_proba) else 0\n",
    "            \n",
    "            results.append({\n",
    "                \"name\": filename,\n",
    "                \"pred\": y,\n",
    "                \"pred_proba\": [real_proba, fake_proba]\n",
    "            })\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "print(\"\\n✓ Processing complete!\")\n",
    "\n",
    "# Save results for submission\n",
    "save_results_to_csv(results, \"submission.csv\", for_submit=True)\n",
    "print(f\"✓ Saved submission to submission.csv\")\n",
    "\n",
    "# Print statistics\n",
    "num_real = sum(1 for r in results if r['pred'] == 0)\n",
    "num_fake = sum(1 for r in results if r['pred'] == 1)\n",
    "print(f\"\\nPrediction Summary:\")\n",
    "print(f\"  Real: {num_real} ({num_real/len(results)*100:.1f}%)\")\n",
    "print(f\"  Fake: {num_fake} ({num_fake/len(results)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ca92d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file : task\n",
      "jupyter notebook\n",
      "제출 완료\n"
     ]
    }
   ],
   "source": [
    "import aifactory.score as aif\n",
    "\n",
    "aif.submit(model_name=\"GenConViT-v1-pad24\",\n",
    "           key=\"012c6af2-e485-4892-b1aa-273486827f7a\"\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab1042",
   "metadata": {},
   "source": [
    "## 2. TRY 2 : 11/12 17:43 -> 0.53? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from models.pred_func import load_genconvit, pred_vid, face_rec, preprocess_frame, is_video, extract_frames\n",
    "from models.config import load_config\n",
    "from typing import List, Dict, Union, Tuple\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import mediapipe as mp\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "# =====================================================================\n",
    "# FACIAL COMPONENT GUIDANCE (FCG) IMPLEMENTATION\n",
    "# Based on DFD-FCG CVPR'25 paper\n",
    "# =====================================================================\n",
    "\n",
    "class FacialComponentAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes key facial components (eyes, nose, lips, skin) to detect deepfakes.\n",
    "    Inspired by DFD-FCG's approach of focusing on critical facial regions.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=True,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Facial component landmark indices (MediaPipe)\n",
    "        self.component_indices = {\n",
    "            'left_eye': list(range(33, 42)) + list(range(133, 145)),\n",
    "            'right_eye': list(range(263, 272)) + list(range(362, 374)),\n",
    "            'nose': list(range(1, 9)) + [168, 197, 195, 5],\n",
    "            'lips': list(range(61, 68)) + list(range(291, 298)) + list(range(375, 380)) + list(range(146, 151)),\n",
    "            'skin': [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,\n",
    "                     397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,\n",
    "                     172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]\n",
    "        }\n",
    "    \n",
    "    def extract_component_regions(self, image: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Extract ROIs for each facial component\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if len(image.shape) == 3 else image\n",
    "        \n",
    "        results = self.face_mesh.process(image_rgb)\n",
    "        component_regions = {}\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = results.multi_face_landmarks[0]\n",
    "            \n",
    "            for component_name, indices in self.component_indices.items():\n",
    "                # Get bounding box for component\n",
    "                x_coords = [landmarks.landmark[i].x * w for i in indices]\n",
    "                y_coords = [landmarks.landmark[i].y * h for i in indices]\n",
    "                \n",
    "                x_min, x_max = int(min(x_coords)), int(max(x_coords))\n",
    "                y_min, y_max = int(min(y_coords)), int(max(y_coords))\n",
    "                \n",
    "                # Add padding\n",
    "                padding = 5\n",
    "                x_min = max(0, x_min - padding)\n",
    "                y_min = max(0, y_min - padding)\n",
    "                x_max = min(w, x_max + padding)\n",
    "                y_max = min(h, y_max + padding)\n",
    "                \n",
    "                component_regions[component_name] = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        return component_regions\n",
    "    \n",
    "    def analyze_component_consistency(self, frames: List[np.ndarray]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Analyze temporal consistency of facial components across frames.\n",
    "        Key insight from FCG: Eyes are most critical for generalization.\n",
    "        \"\"\"\n",
    "        if len(frames) < 2:\n",
    "            return {'eyes_score': 0.0, 'nose_score': 0.0, 'lips_score': 0.0, 'skin_score': 0.0}\n",
    "        \n",
    "        component_scores = {\n",
    "            'eyes_score': [],\n",
    "            'nose_score': [],\n",
    "            'lips_score': [],\n",
    "            'skin_score': []\n",
    "        }\n",
    "        \n",
    "        for i in range(min(len(frames) - 1, 10)):  # Sample up to 10 frame pairs\n",
    "            regions1 = self.extract_component_regions(frames[i])\n",
    "            regions2 = self.extract_component_regions(frames[i + 1])\n",
    "            \n",
    "            for component in ['left_eye', 'right_eye', 'nose', 'lips', 'skin']:\n",
    "                if component not in regions1 or component not in regions2:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate structural similarity\n",
    "                region1 = cv2.resize(regions1[component], (64, 64)) if regions1[component].size > 0 else None\n",
    "                region2 = cv2.resize(regions2[component], (64, 64)) if regions2[component].size > 0 else None\n",
    "                \n",
    "                if region1 is not None and region2 is not None:\n",
    "                    # Compute difference\n",
    "                    diff = np.mean(np.abs(region1.astype(float) - region2.astype(float)))\n",
    "                    \n",
    "                    # Map to score key\n",
    "                    if 'eye' in component:\n",
    "                        component_scores['eyes_score'].append(diff)\n",
    "                    elif component == 'nose':\n",
    "                        component_scores['nose_score'].append(diff)\n",
    "                    elif component == 'lips':\n",
    "                        component_scores['lips_score'].append(diff)\n",
    "                    elif component == 'skin':\n",
    "                        component_scores['skin_score'].append(diff)\n",
    "        \n",
    "        # Average scores\n",
    "        return {\n",
    "            k: np.mean(v) if v else 0.0 \n",
    "            for k, v in component_scores.items()\n",
    "        }\n",
    "    \n",
    "    def detect_component_artifacts(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Detect artifacts in individual components (for images)\"\"\"\n",
    "        component_regions = self.extract_component_regions(image)\n",
    "        artifact_scores = {}\n",
    "        \n",
    "        for component_name, region in component_regions.items():\n",
    "            if region.size == 0:\n",
    "                artifact_scores[component_name] = 0.0\n",
    "                continue\n",
    "            \n",
    "            # Check for artifacts using multiple methods\n",
    "            \n",
    "            # 1. Frequency domain analysis\n",
    "            if len(region.shape) == 3:\n",
    "                gray = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                gray = region\n",
    "            \n",
    "            f_transform = np.fft.fft2(gray)\n",
    "            f_shift = np.fft.fftshift(f_transform)\n",
    "            magnitude = np.abs(f_shift)\n",
    "            \n",
    "            # High frequency ratio\n",
    "            h, w = magnitude.shape\n",
    "            center_h, center_w = h // 2, w // 2\n",
    "            mask_radius = min(h, w) // 4\n",
    "            y, x = np.ogrid[:h, :w]\n",
    "            mask = (x - center_w)**2 + (y - center_h)**2 <= mask_radius**2\n",
    "            \n",
    "            high_freq = magnitude.copy()\n",
    "            high_freq[mask] = 0\n",
    "            \n",
    "            freq_ratio = np.sum(high_freq) / (np.sum(magnitude) + 1e-10)\n",
    "            \n",
    "            # 2. Texture consistency\n",
    "            laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "            texture_var = laplacian.var()\n",
    "            \n",
    "            # Combine metrics\n",
    "            artifact_scores[component_name] = {\n",
    "                'freq_anomaly': freq_ratio,\n",
    "                'texture_var': texture_var\n",
    "            }\n",
    "        \n",
    "        return artifact_scores\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# ENHANCED TEMPORAL ANALYSIS\n",
    "# =====================================================================\n",
    "\n",
    "def analyze_optical_flow(frames: List[np.ndarray]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Optical flow analysis for motion consistency.\n",
    "    Detects unnatural motion patterns in deepfakes.\n",
    "    \"\"\"\n",
    "    if len(frames) < 2:\n",
    "        return {'flow_mean': 0.0, 'flow_variance': 0.0, 'flow_inconsistency': 0.0}\n",
    "    \n",
    "    flow_magnitudes = []\n",
    "    flow_inconsistencies = []\n",
    "    \n",
    "    for i in range(min(len(frames) - 1, 15)):  # Analyze up to 15 frame pairs\n",
    "        frame1 = cv2.cvtColor(frames[i], cv2.COLOR_RGB2GRAY)\n",
    "        frame2 = cv2.cvtColor(frames[i + 1], cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Farneback optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            frame1, frame2, None,\n",
    "            pyr_scale=0.5, levels=3, winsize=15,\n",
    "            iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "        )\n",
    "        \n",
    "        magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "        flow_magnitudes.append(np.mean(magnitude))\n",
    "        \n",
    "        # Detect sudden changes (inconsistency)\n",
    "        if len(flow_magnitudes) > 1:\n",
    "            flow_diff = abs(flow_magnitudes[-1] - flow_magnitudes[-2])\n",
    "            flow_inconsistencies.append(flow_diff)\n",
    "    \n",
    "    mean_flow = np.mean(flow_magnitudes)\n",
    "    flow_var = np.var(flow_magnitudes)\n",
    "    \n",
    "    # Count spikes (sudden motion changes - typical of AI video)\n",
    "    if flow_inconsistencies:\n",
    "        threshold = np.mean(flow_inconsistencies) + 1.5 * np.std(flow_inconsistencies)\n",
    "        num_spikes = sum(1 for x in flow_inconsistencies if x > threshold)\n",
    "    else:\n",
    "        num_spikes = 0\n",
    "    \n",
    "    return {\n",
    "        'flow_mean': mean_flow,\n",
    "        'flow_variance': flow_var,\n",
    "        'flow_inconsistency': np.mean(flow_inconsistencies) if flow_inconsistencies else 0.0,\n",
    "        'flow_spikes': num_spikes\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_temporal_frequency(features_sequence: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    FFT analysis of feature sequences to detect unnatural temporal patterns.\n",
    "    AI-generated videos often have specific frequency signatures.\n",
    "    \"\"\"\n",
    "    if features_sequence.shape[0] < 8:\n",
    "        return {'freq_ratio': 1.0, 'freq_suspicious': False}\n",
    "    \n",
    "    freq_ratios = []\n",
    "    \n",
    "    # Analyze frequency content across feature dimensions\n",
    "    for dim in range(min(features_sequence.shape[1], 100)):  # Sample dimensions\n",
    "        signal = features_sequence[:, dim]\n",
    "        \n",
    "        # FFT\n",
    "        fft_vals = np.fft.fft(signal)\n",
    "        power_spectrum = np.abs(fft_vals) ** 2\n",
    "        \n",
    "        # Low vs high frequency energy\n",
    "        mid_point = len(power_spectrum) // 2\n",
    "        low_freq_energy = np.sum(power_spectrum[:mid_point//4])\n",
    "        high_freq_energy = np.sum(power_spectrum[mid_point//4:mid_point])\n",
    "        \n",
    "        ratio = high_freq_energy / (low_freq_energy + 1e-10)\n",
    "        freq_ratios.append(ratio)\n",
    "    \n",
    "    avg_ratio = np.mean(freq_ratios)\n",
    "    \n",
    "    # AI videos typically have abnormal frequency patterns\n",
    "    is_suspicious = (avg_ratio > 2.5) or (avg_ratio < 0.2)\n",
    "    \n",
    "    return {\n",
    "        'freq_ratio': avg_ratio,\n",
    "        'freq_suspicious': is_suspicious,\n",
    "        'freq_variance': np.var(freq_ratios)\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_laplacian_variance(frames):\n",
    "    \"\"\"Calculate Laplacian variance (sharpness/detail measure)\"\"\"\n",
    "    if len(frames) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    laplacian_vars = []\n",
    "    for frame in frames:\n",
    "        if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = frame\n",
    "        \n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        variance = laplacian.var()\n",
    "        laplacian_vars.append(variance)\n",
    "    \n",
    "    return np.mean(laplacian_vars)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# FEATURE EXTRACTION WITH ENHANCED STATISTICS\n",
    "# =====================================================================\n",
    "\n",
    "def extract_features(model, df, fp16_mode=False):\n",
    "    \"\"\"Extract features and calculate comprehensive statistics\"\"\"\n",
    "    if df.shape[0] == 0:\n",
    "        return None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if fp16_mode:\n",
    "            df = df.half()\n",
    "        features = model.extract_features(df)\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        \n",
    "        feat_stats = {\n",
    "            'mean': features_np.mean(axis=0),\n",
    "            'std': features_np.std(axis=0).mean(),\n",
    "            'num_frames': features_np.shape[0]\n",
    "        }\n",
    "        \n",
    "        if features_np.shape[0] > 1:\n",
    "            # Temporal variance\n",
    "            frame_diffs = np.diff(features_np, axis=0)\n",
    "            feat_stats['temporal_variance'] = np.mean(np.var(frame_diffs, axis=0))\n",
    "            \n",
    "            # Per-frame consistency\n",
    "            per_frame_std = np.std(features_np, axis=1).mean()\n",
    "            feat_stats['per_frame_std'] = per_frame_std\n",
    "            \n",
    "            # Outlier detection\n",
    "            frame_distances = np.linalg.norm(features_np - features_np.mean(axis=0), axis=1)\n",
    "            threshold = np.median(frame_distances) + 2 * np.std(frame_distances)\n",
    "            outlier_ratio = np.sum(frame_distances > threshold) / features_np.shape[0]\n",
    "            feat_stats['outlier_ratio'] = outlier_ratio\n",
    "            \n",
    "            # Feature correlation across time\n",
    "            correlations = []\n",
    "            for i in range(features_np.shape[0] - 1):\n",
    "                corr = np.corrcoef(features_np[i], features_np[i+1])[0, 1]\n",
    "                if not np.isnan(corr):\n",
    "                    correlations.append(corr)\n",
    "            \n",
    "            if correlations:\n",
    "                feat_stats['mean_correlation'] = np.mean(correlations)\n",
    "                feat_stats['correlation_variance'] = np.var(correlations)\n",
    "                \n",
    "                # Detect sudden correlation drops\n",
    "                if len(correlations) > 1:\n",
    "                    drops = [abs(correlations[i] - correlations[i+1]) \n",
    "                            for i in range(len(correlations)-1)]\n",
    "                    feat_stats['max_correlation_drop'] = max(drops) if drops else 0.0\n",
    "        else:\n",
    "            feat_stats['temporal_variance'] = 0.0\n",
    "            feat_stats['per_frame_std'] = np.std(features_np)\n",
    "            feat_stats['outlier_ratio'] = 0.0\n",
    "            feat_stats['mean_correlation'] = 1.0\n",
    "            feat_stats['correlation_variance'] = 0.0\n",
    "            feat_stats['max_correlation_drop'] = 0.0\n",
    "        \n",
    "        return feat_stats\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# CSV UTILITIES\n",
    "# =====================================================================\n",
    "\n",
    "def save_results_to_csv(\n",
    "    results: List[Dict[str, Union[str, int, List[float]]]],\n",
    "    filepath: str,\n",
    "    for_submit=False,\n",
    ") -> None:\n",
    "    \"\"\"Save results to CSV with sorted filenames\"\"\"\n",
    "    sorted_results = sorted(results, key=lambda x: x['name'])\n",
    "    \n",
    "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        row = w.writerow\n",
    "        if for_submit:\n",
    "            row((\"filename\", \"label\"))\n",
    "            for r in sorted_results:\n",
    "                row((r['name'], r['pred']))\n",
    "        else:\n",
    "            row((\"name\", \"pred\", \"pred_proba\"))\n",
    "            for r in sorted_results:\n",
    "                row((r[\"name\"], r[\"pred\"], r[\"pred_proba\"]))\n",
    "\n",
    "\n",
    "def get_files_paths(main_path: str, exs: List[str]) -> List[str]:\n",
    "    \"\"\"Collect all files with specified extensions\"\"\"\n",
    "    exs = {(\".\" + ext.lstrip(\".\")).lower() for ext in exs}\n",
    "    results = []\n",
    "    \n",
    "    for root, _, files in os.walk(main_path):\n",
    "        for fname in files:\n",
    "            abs_path = os.path.abspath(os.path.join(root, fname))\n",
    "            _, ext = os.path.splitext(fname)\n",
    "            if ext.lower() in exs:\n",
    "                results.append(abs_path)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# CPU WORKER FUNCTION\n",
    "# =====================================================================\n",
    "\n",
    "def process_single_file(args):\n",
    "    \"\"\"Worker function: CPU tasks (face detection, Laplacian, optical flow)\"\"\"\n",
    "    file_path, num_frames, consecutive = args\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    try:\n",
    "        if is_video(file_path):\n",
    "            # Extract raw frames\n",
    "            raw_frames = extract_frames(file_path, num_frames, consecutive=consecutive)\n",
    "            \n",
    "            # Detect faces\n",
    "            face_crops, count = face_rec(raw_frames)\n",
    "            \n",
    "            if count > 0:\n",
    "                # Calculate metrics\n",
    "                laplacian_var = calculate_laplacian_variance(face_crops[:count])\n",
    "                \n",
    "                # Optical flow analysis\n",
    "                flow_stats = analyze_optical_flow(face_crops[:count])\n",
    "                \n",
    "                return (filename, face_crops[:count], raw_frames[:count], laplacian_var, \n",
    "                       flow_stats, True, None)  # is_video=True\n",
    "            else:\n",
    "                return (filename, None, None, 0.0, {}, True, None)\n",
    "        else:\n",
    "            # Load image\n",
    "            im = Image.open(file_path).convert('RGB')\n",
    "            arr = np.asarray(im)\n",
    "            \n",
    "            # Detect face\n",
    "            face, count = face_rec([arr])\n",
    "            \n",
    "            if count > 0:\n",
    "                laplacian_var = calculate_laplacian_variance(face[:count])\n",
    "                raw_image = face[0]\n",
    "                return (filename, face[:count], [arr], laplacian_var, {}, False, raw_image)\n",
    "            else:\n",
    "                return (filename, None, None, 0.0, {}, False, None)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (filename, None, None, 0.0, {}, None, str(e))\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# MAIN CONFIGURATION AND EXECUTION\n",
    "# =====================================================================\n",
    "\n",
    "DATA_PATH = \"data\"  # Change this to your test data path\n",
    "NUM_FRAMES = 25\n",
    "FP16_MODE = False\n",
    "CONSECUTIVE_FRAMES = True\n",
    "NUM_WORKERS = None  # None = auto-detect\n",
    "\n",
    "# Model setup\n",
    "net = 'genconvit'\n",
    "ed_weight = 'genconvit_ed_inference'\n",
    "vae_weight = 'genconvit_vae_inference'\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "model = load_genconvit(config, net, ed_weight, vae_weight, FP16_MODE)\n",
    "print(f\"✓ Loaded {net} network\")\n",
    "\n",
    "# Initialize Facial Component Analyzer\n",
    "print(\"Initializing Facial Component Analyzer...\")\n",
    "fcg_analyzer = FacialComponentAnalyzer()\n",
    "print(\"✓ FCG Analyzer ready\")\n",
    "\n",
    "# Collect files\n",
    "all_files = get_files_paths(DATA_PATH, exs=['png', 'jpg', 'jpeg', 'mp4'])\n",
    "print(f\"✓ Found {len(all_files)} files\")\n",
    "\n",
    "# Setup multiprocessing\n",
    "num_workers = NUM_WORKERS if NUM_WORKERS else min(max(1, multiprocessing.cpu_count() - 1), 8)\n",
    "print(f\"✓ Using {num_workers} worker processes\")\n",
    "print(f\"✓ Frame extraction: {'consecutive' if CONSECUTIVE_FRAMES else 'evenly spaced'}\\n\")\n",
    "\n",
    "# Prepare worker arguments\n",
    "worker_args = [(file_path, NUM_FRAMES, CONSECUTIVE_FRAMES) for file_path in all_files]\n",
    "\n",
    "# =====================================================================\n",
    "# MAIN PROCESSING LOOP\n",
    "# =====================================================================\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Start Evaluating with FCG Strategy...\")\n",
    "with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "    with tqdm(total=len(all_files), desc=\"Processing files\") as pbar:\n",
    "        for result in pool.imap_unordered(process_single_file, worker_args):\n",
    "            filename, face_crops, raw_frames, laplacian_var, flow_stats, is_video_file, raw_image = result\n",
    "            \n",
    "            # Check for errors\n",
    "            if isinstance(raw_image, str):  # Error message\n",
    "                print(f\"Error processing {filename}: {raw_image}\")\n",
    "                results.append({\n",
    "                    \"name\": filename,\n",
    "                    \"pred\": 0,\n",
    "                    \"pred_proba\": [0.5, 0.5]\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            # No face detected\n",
    "            if face_crops is None:\n",
    "                results.append({\n",
    "                    \"name\": filename,\n",
    "                    \"pred\": 0,\n",
    "                    \"pred_proba\": [0.5, 0.5]\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            # ===== GPU INFERENCE =====\n",
    "            df = preprocess_frame(face_crops)\n",
    "            if FP16_MODE and df.shape[0] > 0:\n",
    "                df = df.half()\n",
    "            \n",
    "            real_proba, fake_proba = (\n",
    "                pred_vid(df, model)\n",
    "                if df.shape[0] > 0\n",
    "                else (0.5, 0.5)\n",
    "            )\n",
    "            \n",
    "            # Extract features with enhanced statistics\n",
    "            feat_stats = extract_features(model, df, FP16_MODE)\n",
    "            if feat_stats:\n",
    "                feat_stats['laplacian_var'] = laplacian_var\n",
    "            \n",
    "            # ===== FACIAL COMPONENT GUIDANCE (FCG) ANALYSIS =====\n",
    "            fcg_scores = {}\n",
    "            \n",
    "            if is_video_file and raw_frames is not None and len(raw_frames) > 1:\n",
    "                # Temporal component consistency (FCG for videos)\n",
    "                fcg_scores = fcg_analyzer.analyze_component_consistency(raw_frames)\n",
    "                \n",
    "                # Frequency analysis\n",
    "                if feat_stats and df.shape[0] > 0:\n",
    "                    with torch.no_grad():\n",
    "                        features_tensor = model.extract_features(df)\n",
    "                        features_np = features_tensor.detach().cpu().numpy()\n",
    "                    freq_stats = analyze_temporal_frequency(features_np)\n",
    "                    fcg_scores.update(freq_stats)\n",
    "            \n",
    "            elif not is_video_file and raw_image is not None:\n",
    "                # Spatial component artifacts (FCG for images)\n",
    "                component_artifacts = fcg_analyzer.detect_component_artifacts(raw_image)\n",
    "                \n",
    "                # Aggregate component scores\n",
    "                for comp_name, metrics in component_artifacts.items():\n",
    "                    if isinstance(metrics, dict):\n",
    "                        for metric_name, value in metrics.items():\n",
    "                            fcg_scores[f'{comp_name}_{metric_name}'] = value\n",
    "            \n",
    "            # ===== MULTI-LAYER DETECTION WITH FCG =====\n",
    "            temporal_var = feat_stats.get('temporal_variance', 0.0) if feat_stats else 0.0\n",
    "            force_fake = False\n",
    "            \n",
    "            # Thresholds\n",
    "            HIGH_LAPLACIAN = 180\n",
    "            HIGH_TEMPORAL_VAR = 0.02\n",
    "            EXTREME_TEMPORAL_VAR = 0.04\n",
    "            \n",
    "            if is_video_file:\n",
    "                # Get optical flow metrics\n",
    "                flow_inconsistency = flow_stats.get('flow_inconsistency', 0.0)\n",
    "                flow_spikes = flow_stats.get('flow_spikes', 0)\n",
    "                \n",
    "                # FCG: Eyes are most critical (per paper findings)\n",
    "                eyes_inconsistency = fcg_scores.get('eyes_score', 0.0)\n",
    "                \n",
    "                # 1. VEO-style: sharp + jerky motion\n",
    "                if laplacian_var > HIGH_LAPLACIAN and temporal_var > HIGH_TEMPORAL_VAR:\n",
    "                    veo_boost = 1.0 + (temporal_var * 15)\n",
    "                    fake_proba = min(1.0, fake_proba * veo_boost)\n",
    "                    \n",
    "                    if temporal_var > EXTREME_TEMPORAL_VAR or flow_spikes > 3:\n",
    "                        force_fake = True\n",
    "                \n",
    "                # 2. SORA-style: smooth + blurry\n",
    "                elif laplacian_var < HIGH_LAPLACIAN and temporal_var < HIGH_TEMPORAL_VAR:\n",
    "                    if laplacian_var < 50:\n",
    "                        fake_proba = min(1.0, fake_proba * 1.3)\n",
    "                        if laplacian_var < 30:\n",
    "                            force_fake = True\n",
    "                \n",
    "                # 3. Low-quality: blurry + jerky\n",
    "                elif laplacian_var < HIGH_LAPLACIAN and temporal_var > HIGH_TEMPORAL_VAR:\n",
    "                    fake_proba = min(1.0, fake_proba * 1.5)\n",
    "                    force_fake = True\n",
    "                \n",
    "                # 4. FCG-based detection: Eye inconsistency (most reliable per paper)\n",
    "                if eyes_inconsistency > 15.0:  # High eye region changes\n",
    "                    fake_proba = min(1.0, fake_proba * 1.4)\n",
    "                    if eyes_inconsistency > 25.0:\n",
    "                        force_fake = True\n",
    "                \n",
    "                # 5. Frequency domain anomaly\n",
    "                if fcg_scores.get('freq_suspicious', False):\n",
    "                    fake_proba = min(1.0, fake_proba * 1.3)\n",
    "                \n",
    "                # 6. Optical flow spikes\n",
    "                if flow_inconsistency > 5.0 or flow_spikes > 5:\n",
    "                    fake_proba = min(1.0, fake_proba * 1.2)\n",
    "                \n",
    "                # 7. Spatial anomaly\n",
    "                if feat_stats and feat_stats.get('outlier_ratio', 0) > 0.3:\n",
    "                    force_fake = True\n",
    "                \n",
    "                # 8. Feature correlation drops (sudden inconsistency)\n",
    "                if feat_stats and feat_stats.get('max_correlation_drop', 0) > 0.5:\n",
    "                    fake_proba = min(1.0, fake_proba * 1.2)\n",
    "            \n",
    "            else:\n",
    "                # ===== IMAGE DETECTION WITH FCG =====\n",
    "                SHARPNESS_THRESHOLD = 180.0\n",
    "                \n",
    "                # Analyze component-specific artifacts\n",
    "                high_freq_components = 0\n",
    "                for comp_name in ['left_eye', 'right_eye', 'nose', 'lips']:\n",
    "                    freq_key = f'{comp_name}_freq_anomaly'\n",
    "                    if freq_key in fcg_scores:\n",
    "                        freq_val = fcg_scores[freq_key]\n",
    "                        # Abnormal frequency patterns\n",
    "                        if freq_val > 0.15 or freq_val < 0.005:\n",
    "                            high_freq_components += 1\n",
    "                \n",
    "                # If multiple components show artifacts\n",
    "                if high_freq_components >= 2:\n",
    "                    fake_proba = min(1.0, fake_proba * 1.5)\n",
    "                    if high_freq_components >= 3:\n",
    "                        force_fake = True\n",
    "                \n",
    "                # Eye-specific check (most critical per FCG paper)\n",
    "                left_eye_freq = fcg_scores.get('left_eye_freq_anomaly', 0)\n",
    "                right_eye_freq = fcg_scores.get('right_eye_freq_anomaly', 0)\n",
    "                \n",
    "                if (left_eye_freq > 0.12 or left_eye_freq < 0.01) and \\\n",
    "                   (right_eye_freq > 0.12 or right_eye_freq < 0.01):\n",
    "                    fake_proba = min(1.0, fake_proba * 1.4)\n",
    "                \n",
    "                # Extreme sharpness anomalies\n",
    "                if laplacian_var > 250:\n",
    "                    fake_proba = min(1.0, fake_proba * 1.3)\n",
    "                    if laplacian_var > 350:\n",
    "                        force_fake = True\n",
    "                elif laplacian_var < 30:\n",
    "                    fake_proba = min(1.0, fake_proba * 1.2)\n",
    "                    if laplacian_var < 15:\n",
    "                        force_fake = True\n",
    "            \n",
    "            # Final prediction\n",
    "            y = 1 if (force_fake or fake_proba >= real_proba) else 0\n",
    "            \n",
    "            results.append({\n",
    "                \"name\": filename,\n",
    "                \"pred\": y,\n",
    "                \"pred_proba\": [real_proba, fake_proba]\n",
    "            })\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "print(\"\\n✓ Processing complete!\")\n",
    "\n",
    "# Save results\n",
    "save_results_to_csv(results, \"submission.csv\", for_submit=True)\n",
    "print(f\"✓ Saved submission to submission.csv\")\n",
    "\n",
    "# Print statistics\n",
    "num_real = sum(1 for r in results if r['pred'] == 0)\n",
    "num_fake = sum(1 for r in results if r['pred'] == 1)\n",
    "print(f\"\\nPrediction Summary:\")\n",
    "print(f\"  Real: {num_real} ({num_real/len(results)*100:.1f}%)\")\n",
    "print(f\"  Fake: {num_fake} ({num_fake/len(results)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24fa04",
   "metadata": {},
   "source": [
    "## TRY 3 : 11/13 -> 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6d3b2",
   "metadata": {},
   "source": [
    "일단, 예전에 했던 것처럼 확률값의 결과를 한번 알아보았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc943448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from models.pred_func import load_genconvit, face_rec, preprocess_frame, is_video, extract_frames\n",
    "from models.config import load_config\n",
    "from typing import List, Dict, Union\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "\n",
    "def save_frame_probabilities_to_csv(\n",
    "    results: List[Dict[str, Union[str, int, float]]],\n",
    "    filepath: str\n",
    ") -> None:\n",
    "    \"\"\"Save per-frame probabilities to CSV\"\"\"\n",
    "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"filename\", \"frame_idx\", \"real_proba\", \"fake_proba\", \"prediction\"])\n",
    "        for r in results:\n",
    "            w.writerow([r['filename'], r['frame_idx'], r['real_proba'], r['fake_proba'], r['pred']])\n",
    "\n",
    "\n",
    "def save_aggregated_to_json(\n",
    "    results: Dict[str, Dict],\n",
    "    filepath: str\n",
    ") -> None:\n",
    "    \"\"\"Save aggregated statistics to JSON\"\"\"\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def save_submission_csv(\n",
    "    results: List[Dict[str, Union[str, int]]],\n",
    "    filepath: str\n",
    ") -> None:\n",
    "    \"\"\"Save final submission CSV (filename, label)\"\"\"\n",
    "    sorted_results = sorted(results, key=lambda x: x['name'])\n",
    "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"filename\", \"label\"])\n",
    "        for r in sorted_results:\n",
    "            w.writerow([r['name'], r['pred']])\n",
    "\n",
    "\n",
    "def get_files_paths(main_path: str, exs: List[str]) -> List[str]:\n",
    "    \"\"\"Collect all files with specified extensions\"\"\"\n",
    "    exs = {(\".\" + ext.lstrip(\".\")).lower() for ext in exs}\n",
    "    results = []\n",
    "\n",
    "    for root, _, files in os.walk(main_path):\n",
    "        for fname in files:\n",
    "            abs_path = os.path.abspath(os.path.join(root, fname))\n",
    "            _, ext = os.path.splitext(fname)\n",
    "            if ext.lower() in exs:\n",
    "                results.append(abs_path)\n",
    "            else:\n",
    "                print(f\"{fname} is not in [{exs}]. passing...\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_frame_probabilities_video(\n",
    "    file_path: str,\n",
    "    model,\n",
    "    fp16_mode: bool = False,\n",
    "    num_frames: int = 15,\n",
    "):\n",
    "    \"\"\"\n",
    "    비디오에서 각 프레임별 확률값 추출\n",
    "    \n",
    "    Returns:\n",
    "        frame_results: List of per-frame predictions\n",
    "        aggregated: Dictionary with aggregated statistics\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract frames\n",
    "    raw_frames = extract_frames(file_path, num_frames, consecutive=False)\n",
    "    \n",
    "    # Detect faces in each frame\n",
    "    face_crops, count = face_rec(raw_frames)\n",
    "    \n",
    "    frame_results = []\n",
    "    \n",
    "    if count > 0:\n",
    "        # Preprocess faces\n",
    "        df = preprocess_frame(face_crops[:count])\n",
    "        \n",
    "        if fp16_mode and df.shape[0] > 0:\n",
    "            df = df.half()\n",
    "        \n",
    "        if df.shape[0] > 0:\n",
    "            with torch.no_grad():\n",
    "                # Get logits for all frames\n",
    "                outputs = model(df)\n",
    "                \n",
    "                # Calculate probabilities per frame\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                # Extract probabilities for each frame\n",
    "                real_probas = probs[:, 0].cpu().numpy()\n",
    "                fake_probas = probs[:, 1].cpu().numpy()\n",
    "                \n",
    "                # Store per-frame results\n",
    "                for frame_idx, (real_p, fake_p) in enumerate(zip(real_probas, fake_probas)):\n",
    "                    pred = 1 if fake_p >= real_p else 0\n",
    "                    \n",
    "                    frame_results.append({\n",
    "                        'filename': filename,\n",
    "                        'frame_idx': frame_idx,\n",
    "                        'real_proba': float(real_p),\n",
    "                        'fake_proba': float(fake_p),\n",
    "                        'pred': pred\n",
    "                    })\n",
    "            \n",
    "            # Calculate aggregated statistics\n",
    "            avg_real = np.mean(real_probas)\n",
    "            avg_fake = np.mean(fake_probas)\n",
    "            final_pred = 1 if avg_fake >= avg_real else 0\n",
    "            \n",
    "            aggregated = {\n",
    "                'num_frames': len(real_probas),\n",
    "                'avg_real_proba': float(avg_real),\n",
    "                'avg_fake_proba': float(avg_fake),\n",
    "                'std_real_proba': float(np.std(real_probas)),\n",
    "                'std_fake_proba': float(np.std(fake_probas)),\n",
    "                'min_fake_proba': float(np.min(fake_probas)),\n",
    "                'max_fake_proba': float(np.max(fake_probas)),\n",
    "                'final_prediction': final_pred,\n",
    "                'frame_predictions': [\n",
    "                    {\n",
    "                        'frame_idx': i,\n",
    "                        'real_proba': float(real_probas[i]),\n",
    "                        'fake_proba': float(fake_probas[i]),\n",
    "                        'pred': 1 if fake_probas[i] >= real_probas[i] else 0\n",
    "                    }\n",
    "                    for i in range(len(real_probas))\n",
    "                ]\n",
    "            }\n",
    "        else:\n",
    "            # No valid preprocessed frames\n",
    "            aggregated = {\n",
    "                'num_frames': 0,\n",
    "                'avg_real_proba': 0.5,\n",
    "                'avg_fake_proba': 0.5,\n",
    "                'final_prediction': 0,\n",
    "                'frame_predictions': []\n",
    "            }\n",
    "    else:\n",
    "        # No faces detected\n",
    "        aggregated = {\n",
    "            'num_frames': 0,\n",
    "            'avg_real_proba': 0.5,\n",
    "            'avg_fake_proba': 0.5,\n",
    "            'final_prediction': 0,\n",
    "            'frame_predictions': []\n",
    "        }\n",
    "    \n",
    "    return frame_results, aggregated\n",
    "\n",
    "\n",
    "def extract_frame_probabilities_image(\n",
    "    file_path: str,\n",
    "    model,\n",
    "    fp16_mode: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    이미지에서 확률값 추출 (단일 프레임)\n",
    "    \n",
    "    Returns:\n",
    "        frame_results: List with single frame prediction\n",
    "        aggregated: Dictionary with statistics\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    try:\n",
    "        im = Image.open(file_path).convert('RGB')\n",
    "        arr = np.asarray(im)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open image {file_path}: {e}\")\n",
    "        return [], {\n",
    "            'num_frames': 0,\n",
    "            'avg_real_proba': 0.5,\n",
    "            'avg_fake_proba': 0.5,\n",
    "            'final_prediction': 0,\n",
    "            'frame_predictions': []\n",
    "        }\n",
    "    \n",
    "    # Detect face\n",
    "    face, count = face_rec([arr])\n",
    "    \n",
    "    if count > 0:\n",
    "        df = preprocess_frame(face[:count])\n",
    "        \n",
    "        if fp16_mode and df.shape[0] > 0:\n",
    "            df = df.half()\n",
    "        \n",
    "        if df.shape[0] > 0:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(df)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                real_proba = probs[0, 0].cpu().item()\n",
    "                fake_proba = probs[0, 1].cpu().item()\n",
    "                pred = 1 if fake_proba >= real_proba else 0\n",
    "                \n",
    "                frame_results = [{\n",
    "                    'filename': filename,\n",
    "                    'frame_idx': 0,\n",
    "                    'real_proba': float(real_proba),\n",
    "                    'fake_proba': float(fake_proba),\n",
    "                    'pred': pred\n",
    "                }]\n",
    "                \n",
    "                aggregated = {\n",
    "                    'num_frames': 1,\n",
    "                    'avg_real_proba': float(real_proba),\n",
    "                    'avg_fake_proba': float(fake_proba),\n",
    "                    'final_prediction': pred,\n",
    "                    'frame_predictions': [{\n",
    "                        'frame_idx': 0,\n",
    "                        'real_proba': float(real_proba),\n",
    "                        'fake_proba': float(fake_proba),\n",
    "                        'pred': pred\n",
    "                    }]\n",
    "                }\n",
    "        else:\n",
    "            frame_results = []\n",
    "            aggregated = {\n",
    "                'num_frames': 0,\n",
    "                'avg_real_proba': 0.5,\n",
    "                'avg_fake_proba': 0.5,\n",
    "                'final_prediction': 0,\n",
    "                'frame_predictions': []\n",
    "            }\n",
    "    else:\n",
    "        frame_results = []\n",
    "        aggregated = {\n",
    "            'num_frames': 0,\n",
    "            'avg_real_proba': 0.5,\n",
    "            'avg_fake_proba': 0.5,\n",
    "            'final_prediction': 0,\n",
    "            'frame_predictions': []\n",
    "        }\n",
    "    \n",
    "    return frame_results, aggregated\n",
    "\n",
    "\n",
    "def extract_frame_probabilities_path(\n",
    "    file_path: str,\n",
    "    model,\n",
    "    fp16_mode: bool = False,\n",
    "    num_frames: int = 15,\n",
    "):\n",
    "    \"\"\"\n",
    "    파일 경로에서 프레임별 확률 추출 (비디오 또는 이미지)\n",
    "    \"\"\"\n",
    "    if is_video(file_path):\n",
    "        return extract_frame_probabilities_video(file_path, model, fp16_mode, num_frames)\n",
    "    else:\n",
    "        return extract_frame_probabilities_image(file_path, model, fp16_mode)\n",
    "\n",
    "\n",
    "def gen_parser():\n",
    "    parser = argparse.ArgumentParser(\"GenConViT frame probability extraction\")\n",
    "    parser.add_argument(\"--p\", type=str, help=\"video or image path\", default=\"data\")\n",
    "    parser.add_argument(\n",
    "        \"--f\", type=int, help=\"number of frames to process for prediction\", default=30\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--s\", help=\"model size type: tiny, large.\",\n",
    "    )\n",
    "    parser.add_argument(\"--fp16\", action=\"store_true\", help=\"half precision support\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    path = args.p\n",
    "    num_frames = args.f\n",
    "    fp16 = args.fp16\n",
    "\n",
    "    net = 'genconvit'\n",
    "    ed_weight = 'genconvit_ed_inference'\n",
    "    vae_weight = 'genconvit_vae_inference'\n",
    "\n",
    "    if args.s:\n",
    "        if args.s in ['tiny', 'large']:\n",
    "            config[\"model\"][\"backbone\"] = f\"convnext_{args.s}\"\n",
    "            config[\"model\"][\"embedder\"] = f\"swin_{args.s}_patch4_window7_224\"\n",
    "            config[\"model\"][\"type\"] = args.s\n",
    "\n",
    "    return path, num_frames, net, fp16, ed_weight, vae_weight\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 하이퍼 파라미터 정의\n",
    "    path, num_frames, net, fp16, ed_weight, vae_weight = gen_parser()\n",
    "\n",
    "    # 모델 로드\n",
    "    print(\"Loading model...\")\n",
    "    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)\n",
    "    print(f\"✓ Loaded {net} network\")\n",
    "\n",
    "    # 입력 경로에서 이미지/비디오 수집\n",
    "    root_dir = path\n",
    "    all_files = get_files_paths(root_dir, exs=['png', 'jpg', 'jpeg', 'mp4'])\n",
    "    print(f\"✓ Found {len(all_files)} files\")\n",
    "\n",
    "    # 결과 저장용 리스트\n",
    "    all_frame_results = []  # 모든 프레임별 결과\n",
    "    all_aggregated = {}     # 파일별 집계 결과\n",
    "    submission_results = [] # 최종 제출용 결과\n",
    "\n",
    "    print(f\"Start extracting per-frame probabilities...\")\n",
    "    for file_path in tqdm(all_files, total=len(all_files)):\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        # 프레임별 확률 추출\n",
    "        frame_results, aggregated = extract_frame_probabilities_path(\n",
    "            file_path=file_path,\n",
    "            model=model,\n",
    "            fp16_mode=fp16,\n",
    "            num_frames=num_frames,\n",
    "        )\n",
    "        \n",
    "        # 결과 저장\n",
    "        all_frame_results.extend(frame_results)\n",
    "        all_aggregated[filename] = aggregated\n",
    "        \n",
    "        # 최종 제출용 결과\n",
    "        submission_results.append({\n",
    "            'name': filename,\n",
    "            'pred': aggregated['final_prediction']\n",
    "        })\n",
    "\n",
    "    print(\"\\n✓ Processing complete!\")\n",
    "\n",
    "    # ===== 결과 저장 =====\n",
    "    \n",
    "    # 1. 프레임별 확률값 CSV 저장\n",
    "    csv_output = \"frame_probabilities.csv\"\n",
    "    save_frame_probabilities_to_csv(all_frame_results, csv_output)\n",
    "    print(f\"✓ Saved per-frame probabilities to {csv_output}\")\n",
    "\n",
    "    # 2. 파일별 집계 통계 JSON 저장\n",
    "    json_output = \"aggregated_probabilities.json\"\n",
    "    save_aggregated_to_json(all_aggregated, json_output)\n",
    "    print(f\"✓ Saved aggregated statistics to {json_output}\")\n",
    "\n",
    "    # 3. 최종 제출용 CSV 저장\n",
    "    submission_output = \"submission.csv\"\n",
    "    save_submission_csv(submission_results, submission_output)\n",
    "    print(f\"✓ Saved submission to {submission_output}\")\n",
    "\n",
    "    # ===== 통계 출력 =====\n",
    "    print(f\"\\n=== Statistics ===\")\n",
    "    print(f\"Total files processed: {len(all_aggregated)}\")\n",
    "    print(f\"Total frames analyzed: {len(all_frame_results)}\")\n",
    "\n",
    "    # 파일별 예측 통계\n",
    "    num_fake_files = sum(1 for v in all_aggregated.values() if v['final_prediction'] == 1)\n",
    "    num_real_files = len(all_aggregated) - num_fake_files\n",
    "\n",
    "    print(f\"\\nFile-level predictions:\")\n",
    "    print(f\"  Real: {num_real_files} ({num_real_files/len(all_aggregated)*100:.1f}%)\")\n",
    "    print(f\"  Fake: {num_fake_files} ({num_fake_files/len(all_aggregated)*100:.1f}%)\")\n",
    "\n",
    "    # 프레임별 예측 통계\n",
    "    if all_frame_results:\n",
    "        num_fake_frames = sum(1 for r in all_frame_results if r['pred'] == 1)\n",
    "        num_real_frames = len(all_frame_results) - num_fake_frames\n",
    "\n",
    "        print(f\"\\nFrame-level predictions:\")\n",
    "        print(f\"  Real: {num_real_frames} ({num_real_frames/len(all_frame_results)*100:.1f}%)\")\n",
    "        print(f\"  Fake: {num_fake_frames} ({num_fake_frames/len(all_frame_results)*100:.1f}%)\")\n",
    "\n",
    "        # 평균 확률\n",
    "        avg_fake_proba_all = np.mean([r['fake_proba'] for r in all_frame_results])\n",
    "        print(f\"\\nAverage fake probability across all frames: {avg_fake_proba_all:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808fb13",
   "metadata": {},
   "source": [
    "filename,frame_idx,real_proba,fake_proba,prediction\n",
    "sample_image_7.png,0,0.003400923451408744,0.9965991377830505,1\n",
    "sample_image_6.png,0,0.002246193354949355,0.9977537989616394,1\n",
    "sample_image_4.png,0,0.1387469321489334,0.861253023147583,1\n",
    "sample_image_5.png,0,0.0009539324673824012,0.9990460276603699,1\n",
    "sample_image_1.png,0,0.9998745918273926,0.00012533320114016533,0\n",
    "sample_image_2.png,0,0.1822851002216339,0.8177149295806885,1\n",
    "sample_image_3.png,0,0.2030087560415268,0.7969911694526672,1\n",
    "\n",
    "sample_video_1.mp4,0,0.9790687561035156,0.020931314677000046,0\n",
    "sample_video_1.mp4,1,0.9026157855987549,0.0973842442035675,0\n",
    "sample_video_1.mp4,2,0.40101468563079834,0.5989852547645569,1\n",
    "sample_video_1.mp4,3,0.9965033531188965,0.0034966946113854647,0\n",
    "sample_video_1.mp4,4,0.99832683801651,0.001673210645094514,0\n",
    "sample_video_1.mp4,5,0.9953550100326538,0.004644962027668953,0\n",
    "sample_video_1.mp4,6,0.9287091493606567,0.07129091769456863,0\n",
    "sample_video_1.mp4,7,0.29610496759414673,0.7038949728012085,1\n",
    "sample_video_1.mp4,8,0.11226729303598404,0.8877326846122742,1\n",
    "sample_video_1.mp4,9,0.5342972874641418,0.46570277214050293,0\n",
    "sample_video_1.mp4,10,0.11400090903043747,0.8859990239143372,1\n",
    "sample_video_1.mp4,11,0.9997707009315491,0.0002292477583978325,0\n",
    "sample_video_1.mp4,12,0.9995256662368774,0.0004744052712339908,0\n",
    "sample_video_1.mp4,13,0.9538599848747253,0.04614001885056496,0\n",
    "sample_video_1.mp4,14,0.9768911004066467,0.02310883440077305,0\n",
    "sample_video_1.mp4,15,0.0006715818308293819,0.9993284940719604,1\n",
    "sample_video_1.mp4,16,8.202696335501969e-05,0.9999179840087891,1\n",
    "sample_video_1.mp4,17,7.666852616239339e-05,0.9999233484268188,1\n",
    "sample_video_1.mp4,18,0.168125718832016,0.8318743109703064,1\n",
    "sample_video_1.mp4,19,0.9399539828300476,0.060045965015888214,0\n",
    "sample_video_1.mp4,20,0.887516975402832,0.11248297989368439,0\n",
    "sample_video_1.mp4,21,0.05511385574936867,0.9448862075805664,1\n",
    "sample_video_1.mp4,22,0.2918016314506531,0.7081984281539917,1\n",
    "sample_video_1.mp4,23,0.2077609747648239,0.7922390103340149,1\n",
    "sample_video_1.mp4,24,0.02328997664153576,0.9767100214958191,1\n",
    "sample_video_1.mp4,25,0.001251019537448883,0.9987490177154541,1\n",
    "sample_video_1.mp4,26,0.7551747560501099,0.24482528865337372,0\n",
    "sample_video_1.mp4,27,0.7623976469039917,0.2376023679971695,0\n",
    "sample_video_1.mp4,28,1.4420808838622179e-05,0.9999855756759644,1\n",
    "sample_video_1.mp4,29,0.0018300967058166862,0.9981698989868164,1\n",
    "\n",
    "\n",
    "sample_video_2.mp4,0,0.552285373210907,0.4477146565914154,0\n",
    "sample_video_2.mp4,1,0.6470654010772705,0.3529345989227295,0\n",
    "sample_video_2.mp4,2,0.0025786624755710363,0.997421383857727,1\n",
    "sample_video_2.mp4,3,0.9894221425056458,0.01057778112590313,0\n",
    "sample_video_2.mp4,4,0.6920812726020813,0.3079186677932739,0\n",
    "sample_video_2.mp4,5,0.9251995086669922,0.0748005285859108,0\n",
    "sample_video_2.mp4,6,0.9979808926582336,0.002019119681790471,0\n",
    "sample_video_2.mp4,7,0.9997732043266296,0.00022678310051560402,0\n",
    "sample_video_2.mp4,8,0.9997422099113464,0.0002578355197329074,0\n",
    "sample_video_2.mp4,9,0.9299098253250122,0.07009012997150421,0\n",
    "sample_video_2.mp4,10,0.2362697720527649,0.7637302279472351,1\n",
    "sample_video_2.mp4,11,0.3207833170890808,0.6792166829109192,1\n",
    "sample_video_2.mp4,12,0.689947783946991,0.3100522458553314,0\n",
    "sample_video_2.mp4,13,0.009349594824016094,0.9906504154205322,1\n",
    "sample_video_2.mp4,14,0.9999815225601196,1.853395951911807e-05,0\n",
    "sample_video_2.mp4,15,0.9996504783630371,0.0003495640412438661,0\n",
    "sample_video_2.mp4,16,0.9984470009803772,0.0015530155505985022,0\n",
    "sample_video_2.mp4,17,0.9999986886978149,1.3264098015497439e-06,0\n",
    "sample_video_2.mp4,18,0.9976486563682556,0.0023513250052928925,0\n",
    "sample_video_2.mp4,19,0.9992438554763794,0.0007561193197034299,0\n",
    "sample_video_2.mp4,20,0.9577920436859131,0.04220796748995781,0\n",
    "sample_video_2.mp4,21,0.9998151659965515,0.00018483144231140614,0\n",
    "sample_video_2.mp4,22,0.9783141016960144,0.021685883402824402,0\n",
    "sample_video_2.mp4,23,1.0,3.3712160840693173e-10,0\n",
    "sample_video_2.mp4,24,0.9816708564758301,0.018329113721847534,0\n",
    "sample_video_2.mp4,25,0.9990838766098022,0.0009161198977380991,0\n",
    "sample_video_2.mp4,26,0.9988237023353577,0.0011763233924284577,0\n",
    "sample_video_2.mp4,27,0.9939069151878357,0.006093055475503206,0\n",
    "\n",
    "\n",
    "sample_video_3.mp4,0,2.231787766504567e-05,0.999977707862854,1\n",
    "sample_video_3.mp4,1,2.8047297746525146e-05,0.9999719858169556,1\n",
    "sample_video_3.mp4,2,1.0130503142136149e-05,0.9999898672103882,1\n",
    "sample_video_3.mp4,3,3.5431723517831415e-05,0.9999645948410034,1\n",
    "sample_video_3.mp4,4,0.0003543641942087561,0.9996455907821655,1\n",
    "sample_video_3.mp4,5,0.10812240093946457,0.8918775916099548,1\n",
    "sample_video_3.mp4,6,0.00042190373642370105,0.999578058719635,1\n",
    "sample_video_3.mp4,7,0.024075962603092194,0.9759240746498108,1\n",
    "sample_video_3.mp4,8,0.035062022507190704,0.9649379253387451,1\n",
    "sample_video_3.mp4,9,0.01316155306994915,0.9868384003639221,1\n",
    "sample_video_3.mp4,10,0.0010301542934030294,0.9989699125289917,1\n",
    "sample_video_3.mp4,11,0.001404339331202209,0.998595654964447,1\n",
    "sample_video_3.mp4,12,0.003312255721539259,0.9966877102851868,1\n",
    "sample_video_3.mp4,13,0.02376420609652996,0.9762358069419861,1\n",
    "sample_video_3.mp4,14,0.01845422014594078,0.9815457463264465,1\n",
    "sample_video_3.mp4,15,0.0009211369324475527,0.9990788698196411,1\n",
    "sample_video_3.mp4,16,4.310508302296512e-05,0.9999568462371826,1\n",
    "sample_video_3.mp4,17,0.007463885936886072,0.992536187171936,1\n",
    "sample_video_3.mp4,18,0.9999988079071045,1.14704209863703e-06,0\n",
    "sample_video_3.mp4,19,0.9965841770172119,0.0034157640766352415,0\n",
    "sample_video_3.mp4,20,6.028825794146542e-08,0.9999998807907104,1\n",
    "sample_video_3.mp4,21,0.09927377104759216,0.9007261991500854,1\n",
    "sample_video_3.mp4,22,0.29918229579925537,0.7008176445960999,1\n",
    "sample_video_3.mp4,23,0.5502461791038513,0.4497537314891815,0\n",
    "sample_video_3.mp4,24,0.01758238673210144,0.982417643070221,1\n",
    "sample_video_3.mp4,25,0.007076663430780172,0.992923378944397,1\n",
    "sample_video_3.mp4,26,0.04972818121314049,0.9502717852592468,1\n",
    "sample_video_3.mp4,27,0.048936303704977036,0.9510636925697327,1\n",
    "\n",
    "\n",
    "sample_video_4.mp4,0,0.00011951888154726475,0.9998804330825806,1\n",
    "sample_video_4.mp4,1,3.800360354944132e-05,0.9999619722366333,1\n",
    "sample_video_4.mp4,2,9.566800144966692e-05,0.9999042749404907,1\n",
    "sample_video_4.mp4,3,0.004657244775444269,0.9953427314758301,1\n",
    "sample_video_4.mp4,4,0.00039227845263667405,0.9996077418327332,1\n",
    "sample_video_4.mp4,5,0.0008691847324371338,0.9991307854652405,1\n",
    "sample_video_4.mp4,6,0.002691729459911585,0.9973082542419434,1\n",
    "sample_video_4.mp4,7,0.0007344328914768994,0.9992656111717224,1\n",
    "sample_video_4.mp4,8,0.24086201190948486,0.7591379284858704,1\n",
    "sample_video_4.mp4,9,0.03669920936226845,0.9633007645606995,1\n",
    "sample_video_4.mp4,10,0.8813573122024536,0.11864274740219116,0\n",
    "sample_video_4.mp4,11,2.5278695829911157e-06,0.9999974966049194,1\n",
    "sample_video_4.mp4,12,0.0002221961331088096,0.9997778534889221,1\n",
    "sample_video_4.mp4,13,0.009309524670243263,0.9906904697418213,1\n",
    "sample_video_4.mp4,14,0.015877963975071907,0.9841220378875732,1\n",
    "sample_video_4.mp4,15,1.5118233775979206e-08,1.0,1\n",
    "sample_video_5.mp4,0,0.00012067541683791205,0.9998793601989746,1\n",
    "sample_video_5.mp4,1,0.9647229909896851,0.035277046263217926,0\n",
    "sample_video_5.mp4,2,0.9860543608665466,0.013945622369647026,0\n",
    "sample_video_5.mp4,3,0.9991369843482971,0.0008630394004285336,0\n",
    "sample_video_5.mp4,4,0.9998331069946289,0.0001668316253926605,0\n",
    "sample_video_5.mp4,5,0.9976425766944885,0.002357346937060356,0\n",
    "sample_video_5.mp4,6,0.9635066986083984,0.03649332374334335,0\n",
    "sample_video_5.mp4,7,0.9907829165458679,0.009217056445777416,0\n",
    "sample_video_5.mp4,8,0.6926249861717224,0.3073749840259552,0\n",
    "sample_video_5.mp4,9,0.9804189801216125,0.019580954685807228,0\n",
    "sample_video_5.mp4,10,0.47934260964393616,0.5206574201583862,1\n",
    "sample_video_5.mp4,11,0.977471649646759,0.022528300061821938,0\n",
    "sample_video_5.mp4,12,0.40261024236679077,0.5973897576332092,1\n",
    "sample_video_5.mp4,13,0.9825249910354614,0.01747497357428074,0\n",
    "sample_video_5.mp4,14,0.37024402618408203,0.629755973815918,1\n",
    "sample_video_5.mp4,15,6.316122380667366e-06,0.9999936819076538,1\n",
    "sample_video_5.mp4,16,0.9905055165290833,0.009494493715465069,0\n",
    "sample_video_5.mp4,17,0.9337236881256104,0.06627634912729263,0\n",
    "sample_video_5.mp4,18,0.9441015124320984,0.0558985136449337,0\n",
    "sample_video_5.mp4,19,0.9998006224632263,0.00019945681560784578,0\n",
    "sample_video_5.mp4,20,0.7776525616645813,0.22234748303890228,0\n",
    "sample_video_5.mp4,21,0.9942375421524048,0.005762387067079544,0\n",
    "sample_video_5.mp4,22,0.9925923347473145,0.007407746277749538,0\n",
    "sample_video_5.mp4,23,0.8768342733383179,0.12316570430994034,0\n",
    "sample_video_5.mp4,24,0.5414329767227173,0.4585671126842499,0\n",
    "sample_video_5.mp4,25,0.7917376160621643,0.2082623690366745,0\n",
    "sample_video_5.mp4,26,0.9312676787376404,0.06873229891061783,0\n",
    "sample_video_5.mp4,27,0.6853089928627014,0.3146910071372986,0\n",
    "sample_video_5.mp4,28,0.9970850348472595,0.002914972370490432,0\n",
    "sample_video_5.mp4,29,0.9671662449836731,0.0328337661921978,0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207bd81",
   "metadata": {},
   "source": [
    "병렬 처리 + frame 확률 계산 ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b469ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from models.pred_func import load_genconvit, face_rec, preprocess_frame, is_video, extract_frames\n",
    "from models.config import load_config\n",
    "from typing import List, Dict, Union\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "import multiprocessing\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# CPU WORKER FUNCTION FOR PARALLEL PROCESSING\n",
    "# =====================================================================\n",
    "\n",
    "def process_single_file_cpu(args):\n",
    "    \"\"\"CPU 작업: 프레임 추출 및 얼굴 검출\"\"\"\n",
    "    file_path, num_frames = args\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    try:\n",
    "        if is_video(file_path):\n",
    "            # Extract frames\n",
    "            raw_frames = extract_frames(file_path, num_frames, consecutive=False)\n",
    "            \n",
    "            # Detect faces\n",
    "            face_crops, count = face_rec(raw_frames)\n",
    "            \n",
    "            if count > 0:\n",
    "                # Calculate Laplacian variance for each frame\n",
    "                laplacian_vars = []\n",
    "                for face in face_crops[:count]:\n",
    "                    if len(face.shape) == 3:\n",
    "                        gray = cv2.cvtColor(face, cv2.COLOR_RGB2GRAY)\n",
    "                    else:\n",
    "                        gray = face\n",
    "                    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "                    laplacian_vars.append(laplacian.var())\n",
    "                \n",
    "                return (filename, face_crops[:count], raw_frames[:count], laplacian_vars, True, None)\n",
    "            else:\n",
    "                return (filename, None, None, [], True, None)\n",
    "        else:\n",
    "            # Load image\n",
    "            im = Image.open(file_path).convert('RGB')\n",
    "            arr = np.asarray(im)\n",
    "            \n",
    "            # Detect face\n",
    "            face, count = face_rec([arr])\n",
    "            \n",
    "            if count > 0:\n",
    "                face_crop = face[0]\n",
    "                if len(face_crop.shape) == 3:\n",
    "                    gray = cv2.cvtColor(face_crop, cv2.COLOR_RGB2GRAY)\n",
    "                else:\n",
    "                    gray = face_crop\n",
    "                laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "                lap_var = laplacian.var()\n",
    "                \n",
    "                return (filename, face[:count], [arr], [lap_var], False, None)\n",
    "            else:\n",
    "                return (filename, None, None, [], False, None)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (filename, None, None, [], None, str(e))\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# TEMPORAL ANALYSIS\n",
    "# =====================================================================\n",
    "\n",
    "def calculate_temporal_variance(frames_np):\n",
    "    \"\"\"프레임 간 optical flow의 분산 계산\"\"\"\n",
    "    if len(frames_np) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    normalized_frames = []\n",
    "    \n",
    "    for frame in frames_np:\n",
    "        if len(frame.shape) == 3:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = frame\n",
    "        \n",
    "        if gray.shape[:2] != target_size:\n",
    "            gray = cv2.resize(gray, target_size, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        normalized_frames.append(gray)\n",
    "    \n",
    "    prev_gray = None\n",
    "    magnitudes = []\n",
    "    \n",
    "    for gray in normalized_frames:\n",
    "        if prev_gray is not None:\n",
    "            try:\n",
    "                flow = cv2.calcOpticalFlowFarneback(\n",
    "                    prev_gray, gray, None, \n",
    "                    pyr_scale=0.5, levels=3, winsize=15, \n",
    "                    iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "                )\n",
    "                mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "                magnitudes.append(np.mean(mag))\n",
    "            except cv2.error:\n",
    "                continue\n",
    "        \n",
    "        prev_gray = gray\n",
    "    \n",
    "    return np.var(magnitudes) if magnitudes else 0.0\n",
    "\n",
    "\n",
    "def calculate_detail_stability(laplacian_vars):\n",
    "    \"\"\"프레임 간 디테일(선명도)의 일관성 측정\"\"\"\n",
    "    if len(laplacian_vars) < 2:\n",
    "        return 0.0\n",
    "    return np.std(laplacian_vars)\n",
    "\n",
    "\n",
    "def classify_video_type(temporal_var, detail_stability, avg_sharpness):\n",
    "    \"\"\"비디오 타입 분류\"\"\"\n",
    "    TEMPORAL_HIGH = 0.03\n",
    "    TEMPORAL_LOW = 0.01\n",
    "    DETAIL_HIGH = 50.0\n",
    "    DETAIL_LOW = 30.0\n",
    "    SHARP_THRESHOLD = 150.0\n",
    "    \n",
    "    if avg_sharpness > SHARP_THRESHOLD and temporal_var > TEMPORAL_HIGH:\n",
    "        return True, 0.85, \"VEO3-type\"\n",
    "    \n",
    "    if avg_sharpness < SHARP_THRESHOLD and temporal_var < TEMPORAL_LOW and detail_stability > DETAIL_HIGH:\n",
    "        return True, 0.80, \"SORA2-type\"\n",
    "    \n",
    "    if detail_stability > DETAIL_HIGH and temporal_var > TEMPORAL_HIGH:\n",
    "        return True, 0.75, \"Hybrid-type\"\n",
    "    \n",
    "    if detail_stability < DETAIL_LOW and TEMPORAL_LOW < temporal_var < TEMPORAL_HIGH:\n",
    "        return False, 0.90, \"Real-type\"\n",
    "    \n",
    "    return None, 0.5, \"Uncertain-type\"\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# ARTIFACT DETECTION\n",
    "# =====================================================================\n",
    "\n",
    "def check_frequency_artifacts(image):\n",
    "    \"\"\"주파수 도메인에서 deepfake artifacts 검사\"\"\"\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image.convert('L'))\n",
    "    \n",
    "    f_transform = np.fft.fft2(image)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "    magnitude_spectrum = np.abs(f_shift)\n",
    "    \n",
    "    h, w = magnitude_spectrum.shape\n",
    "    center_h, center_w = h // 2, w // 2\n",
    "    \n",
    "    high_freq_region = magnitude_spectrum.copy()\n",
    "    mask_radius = min(h, w) // 4\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    mask = (x - center_w)**2 + (y - center_h)**2 <= mask_radius**2\n",
    "    high_freq_region[mask] = 0\n",
    "    \n",
    "    total_energy = np.sum(magnitude_spectrum)\n",
    "    high_freq_energy = np.sum(high_freq_region)\n",
    "    high_freq_ratio = high_freq_energy / (total_energy + 1e-10)\n",
    "    \n",
    "    return high_freq_ratio\n",
    "\n",
    "\n",
    "def check_face_boundary_artifacts(image):\n",
    "    \"\"\"얼굴 경계선 주변의 artifacts 검사\"\"\"\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    border_width = int(min(h, w) * 0.1)\n",
    "    \n",
    "    top_border = image[:border_width, :]\n",
    "    bottom_border = image[-border_width:, :]\n",
    "    left_border = image[:, :border_width]\n",
    "    right_border = image[:, -border_width:]\n",
    "    \n",
    "    border_regions = [top_border, bottom_border, left_border, right_border]\n",
    "    border_stds = [np.std(region) for region in border_regions]\n",
    "    avg_border_std = np.mean(border_stds)\n",
    "    \n",
    "    center_region = image[border_width:-border_width, border_width:-border_width]\n",
    "    center_std = np.std(center_region)\n",
    "    \n",
    "    boundary_anomaly = abs(avg_border_std - center_std) / (center_std + 1e-10)\n",
    "    return boundary_anomaly\n",
    "\n",
    "\n",
    "def check_color_consistency(image):\n",
    "    \"\"\"색상 일관성 검사\"\"\"\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    \n",
    "    r_mean = np.mean(image[:,:,0])\n",
    "    g_mean = np.mean(image[:,:,1])\n",
    "    b_mean = np.mean(image[:,:,2])\n",
    "    channel_imbalance = np.std([r_mean, g_mean, b_mean]) / (np.mean([r_mean, g_mean, b_mean]) + 1e-10)\n",
    "    \n",
    "    return channel_imbalance\n",
    "\n",
    "\n",
    "def perform_secondary_checks(image, laplacian_var):\n",
    "    \"\"\"선명한 이미지에 대한 추가 검증\"\"\"\n",
    "    freq_artifact = check_frequency_artifacts(image)\n",
    "    boundary_artifact = check_face_boundary_artifacts(image)\n",
    "    color_inconsistency = check_color_consistency(image)\n",
    "    \n",
    "    freq_score = 0.0\n",
    "    if freq_artifact < 0.01 or freq_artifact > 0.12:\n",
    "        freq_score = min(abs(freq_artifact - 0.05) / 0.05, 1.0)\n",
    "    \n",
    "    boundary_score = min(boundary_artifact / 1.0, 1.0)\n",
    "    color_score = min(color_inconsistency / 0.5, 1.0)\n",
    "    \n",
    "    weights = {'freq': 0.5, 'boundary': 0.2, 'color': 0.3}\n",
    "    \n",
    "    suspicion_score = (\n",
    "        weights['freq'] * freq_score +\n",
    "        weights['boundary'] * boundary_score +\n",
    "        weights['color'] * color_score\n",
    "    )\n",
    "    \n",
    "    return suspicion_score\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# CSV SAVE FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def save_results_to_csv(results: List[Dict], filepath: str, for_submit=False) -> None:\n",
    "    \"\"\"최종 제출용 CSV 저장\"\"\"\n",
    "    sorted_results = sorted(results, key=lambda x: x['name'])\n",
    "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if for_submit:\n",
    "            w.writerow((\"filename\", \"label\"))\n",
    "            for r in sorted_results:\n",
    "                w.writerow((r['name'], r['pred']))\n",
    "        else:\n",
    "            w.writerow((\"name\", \"pred\", \"pred_proba\"))\n",
    "            for r in sorted_results:\n",
    "                w.writerow((r[\"name\"], r[\"pred\"], r[\"pred_proba\"]))\n",
    "\n",
    "\n",
    "def save_frame_probabilities_to_csv(results: List[Dict], filepath: str) -> None:\n",
    "    \"\"\"프레임별 확률 CSV 저장\"\"\"\n",
    "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"filename\", \"frame_idx\", \"real_proba\", \"fake_proba\", \"prediction\"])\n",
    "        for r in results:\n",
    "            w.writerow([r['filename'], r['frame_idx'], r['real_proba'], r['fake_proba'], r['pred']])\n",
    "\n",
    "\n",
    "def get_files_paths(main_path: str, exs: List[str]) -> List[str]:\n",
    "    \"\"\"파일 경로 수집\"\"\"\n",
    "    exs = {(\".\" + ext.lstrip(\".\")).lower() for ext in exs}\n",
    "    results = []\n",
    "\n",
    "    for root, _, files in os.walk(main_path):\n",
    "        for fname in files:\n",
    "            abs_path = os.path.abspath(os.path.join(root, fname))\n",
    "            _, ext = os.path.splitext(fname)\n",
    "            if ext.lower() in exs:\n",
    "                results.append(abs_path)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# PREDICTION FUNCTIONS WITH POSTPROCESSING\n",
    "# =====================================================================\n",
    "\n",
    "def predict_video(\n",
    "    file_path: str,\n",
    "    model,\n",
    "    fp16_mode: bool = False,\n",
    "    num_frames: int = 15,\n",
    "):\n",
    "    \"\"\"비디오 예측 with 강력한 postprocessing\"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract frames\n",
    "    raw_frames = extract_frames(file_path, num_frames, consecutive=False)\n",
    "    \n",
    "    # Detect faces\n",
    "    face_crops, count = face_rec(raw_frames)\n",
    "    \n",
    "    frame_results = []\n",
    "    \n",
    "    if count > 0:\n",
    "        # Preprocess\n",
    "        df = preprocess_frame(face_crops[:count])\n",
    "        \n",
    "        if fp16_mode and df.shape[0] > 0:\n",
    "            df = df.half()\n",
    "        \n",
    "        if df.shape[0] > 0:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(df)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                real_probas = probs[:, 0].cpu().numpy()\n",
    "                fake_probas = probs[:, 1].cpu().numpy()\n",
    "                \n",
    "                # Store per-frame results\n",
    "                for frame_idx, (real_p, fake_p) in enumerate(zip(real_probas, fake_probas)):\n",
    "                    pred = 1 if fake_p >= real_p else 0\n",
    "                    frame_results.append({\n",
    "                        'filename': filename,\n",
    "                        'frame_idx': frame_idx,\n",
    "                        'real_proba': float(real_p),\n",
    "                        'fake_proba': float(fake_p),\n",
    "                        'pred': pred\n",
    "                    })\n",
    "            \n",
    "            # Calculate average\n",
    "            avg_real = np.mean(real_probas)\n",
    "            avg_fake = np.mean(fake_probas)\n",
    "            predicted_class = 1 if avg_fake >= avg_real else 0\n",
    "            \n",
    "            # ===== POSTPROCESSING: 더 공격적으로 FAKE 탐지 =====\n",
    "            \n",
    "            # 1. Sequence analysis - 임계값 낮춤 (더 민감하게)\n",
    "            if df.shape[0] > 5:\n",
    "                window_size = 5\n",
    "                moving_avg = np.convolve(fake_probas, np.ones(window_size)/window_size, mode=\"valid\")\n",
    "                \n",
    "                high_fake_ratio = np.mean(moving_avg > 0.45)  # 0.55 -> 0.45\n",
    "                mid_fake_ratio = np.mean(moving_avg > 0.35)   # 0.4 -> 0.35\n",
    "                max_moving_avg = np.max(moving_avg)\n",
    "                avg_fake_prob = np.mean(fake_probas)\n",
    "                \n",
    "                # 더 낮은 임계값으로 FAKE 판정\n",
    "                if (high_fake_ratio > 0.12 or mid_fake_ratio > 0.30 or \n",
    "                    max_moving_avg > 0.55 or avg_fake_prob > 0.30):\n",
    "                    predicted_class = 1\n",
    "                    print(f\"[SEQ-OVERRIDE] {filename}: high={high_fake_ratio:.2f}, mid={mid_fake_ratio:.2f}, max={max_moving_avg:.2f}, avg={avg_fake_prob:.2f}\")\n",
    "            \n",
    "            # 2. 프레임 간 변동성 체크 - FAKE 프레임이 하나라도 많으면 의심\n",
    "            fake_frame_count = np.sum(fake_probas > 0.5)\n",
    "            fake_frame_ratio = fake_frame_count / len(fake_probas)\n",
    "            \n",
    "            if fake_frame_ratio > 0.25:  # 25% 이상이 fake면 전체를 fake로\n",
    "                predicted_class = 1\n",
    "                print(f\"[FRAME-RATIO-OVERRIDE] {filename}: {fake_frame_ratio:.2%} frames are fake\")\n",
    "            \n",
    "            # 3. Temporal analysis\n",
    "            if len(raw_frames) >= 5:\n",
    "                # Calculate Laplacian variance\n",
    "                laplacian_vars = []\n",
    "                for face in face_crops[:count]:\n",
    "                    if len(face.shape) == 3:\n",
    "                        gray = cv2.cvtColor(face, cv2.COLOR_RGB2GRAY)\n",
    "                    else:\n",
    "                        gray = face\n",
    "                    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "                    laplacian_vars.append(laplacian.var())\n",
    "                \n",
    "                temporal_var = calculate_temporal_variance(raw_frames)\n",
    "                detail_stability = calculate_detail_stability(laplacian_vars)\n",
    "                avg_sharpness = np.mean(laplacian_vars)\n",
    "                \n",
    "                is_fake_temporal, temp_confidence, video_type = classify_video_type(\n",
    "                    temporal_var, detail_stability, avg_sharpness\n",
    "                )\n",
    "                \n",
    "                if is_fake_temporal is not None and is_fake_temporal:\n",
    "                    predicted_class = 1\n",
    "                    print(f\"[TEMPORAL-OVERRIDE] {filename}: {video_type}\")\n",
    "            \n",
    "            result = {\n",
    "                \"name\": filename,\n",
    "                \"pred\": predicted_class,\n",
    "                \"pred_proba\": [float(avg_real), float(avg_fake)],\n",
    "                \"frame_results\": frame_results\n",
    "            }\n",
    "        else:\n",
    "            result = {\n",
    "                \"name\": filename,\n",
    "                \"pred\": 0,\n",
    "                \"pred_proba\": [0.5, 0.5],\n",
    "                \"frame_results\": []\n",
    "            }\n",
    "    else:\n",
    "        result = {\n",
    "            \"name\": filename,\n",
    "            \"pred\": 0,\n",
    "            \"pred_proba\": [0.5, 0.5],\n",
    "            \"frame_results\": []\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def predict_image(\n",
    "    file_path: str,\n",
    "    model,\n",
    "    fp16_mode: bool = False,\n",
    "):\n",
    "    \"\"\"이미지 예측 with postprocessing\"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    try:\n",
    "        im = Image.open(file_path).convert('RGB')\n",
    "        arr = np.asarray(im)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open image {file_path}: {e}\")\n",
    "        return {\n",
    "            \"name\": filename,\n",
    "            \"pred\": 0,\n",
    "            \"pred_proba\": [0.5, 0.5],\n",
    "            \"frame_results\": []\n",
    "        }\n",
    "    \n",
    "    # Detect face\n",
    "    face, count = face_rec([arr])\n",
    "    \n",
    "    if count > 0:\n",
    "        df = preprocess_frame(face[:count])\n",
    "        \n",
    "        if fp16_mode and df.shape[0] > 0:\n",
    "            df = df.half()\n",
    "        \n",
    "        if df.shape[0] > 0:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(df)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                real_proba = probs[0, 0].cpu().item()\n",
    "                fake_proba = probs[0, 1].cpu().item()\n",
    "                predicted_class = 1 if fake_proba >= real_proba else 0\n",
    "                \n",
    "                # ===== POSTPROCESSING: Secondary checks for high sharpness =====\n",
    "                face_crop = face[0]\n",
    "                if len(face_crop.shape) == 3:\n",
    "                    gray = cv2.cvtColor(face_crop, cv2.COLOR_RGB2GRAY)\n",
    "                else:\n",
    "                    gray = face_crop\n",
    "                laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "                lap_var = laplacian.var()\n",
    "                \n",
    "                SHARPNESS_THRESHOLD = 180.0\n",
    "                \n",
    "                if lap_var > SHARPNESS_THRESHOLD and predicted_class == 0:\n",
    "                    suspicion_score = perform_secondary_checks(face_crop, lap_var)\n",
    "                    \n",
    "                    SUSPICION_THRESHOLD = 0.60\n",
    "                    \n",
    "                    if suspicion_score > SUSPICION_THRESHOLD:\n",
    "                        predicted_class = 1\n",
    "                        print(f\"[OVERRIDE] {filename}: Sharp but suspicious (susp={suspicion_score:.3f}, lap={lap_var:.1f})\")\n",
    "                \n",
    "                frame_results = [{\n",
    "                    'filename': filename,\n",
    "                    'frame_idx': 0,\n",
    "                    'real_proba': float(real_proba),\n",
    "                    'fake_proba': float(fake_proba),\n",
    "                    'pred': predicted_class\n",
    "                }]\n",
    "                \n",
    "                result = {\n",
    "                    \"name\": filename,\n",
    "                    \"pred\": predicted_class,\n",
    "                    \"pred_proba\": [float(real_proba), float(fake_proba)],\n",
    "                    \"frame_results\": frame_results\n",
    "                }\n",
    "        else:\n",
    "            result = {\n",
    "                \"name\": filename,\n",
    "                \"pred\": 0,\n",
    "                \"pred_proba\": [0.5, 0.5],\n",
    "                \"frame_results\": []\n",
    "            }\n",
    "    else:\n",
    "        result = {\n",
    "            \"name\": filename,\n",
    "            \"pred\": 0,\n",
    "            \"pred_proba\": [0.5, 0.5],\n",
    "            \"frame_results\": []\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def predict_path(\n",
    "    file_path: str,\n",
    "    model,\n",
    "    fp16_mode: bool = False,\n",
    "    num_frames: int = 15,\n",
    "):\n",
    "    \"\"\"파일 타입에 따라 예측\"\"\"\n",
    "    if is_video(file_path):\n",
    "        return predict_video(file_path, model, fp16_mode=fp16_mode, num_frames=num_frames)\n",
    "    else:\n",
    "        return predict_image(file_path, model, fp16_mode=fp16_mode)\n",
    "\n",
    "\n",
    "def gen_parser():\n",
    "    parser = argparse.ArgumentParser(\"GenConViT prediction with postprocessing\")\n",
    "    parser.add_argument(\"--p\", type=str, help=\"video or image path\", default=\"data\")\n",
    "    parser.add_argument(\"--f\", type=int, help=\"number of frames to process\", default=15)\n",
    "    parser.add_argument(\"--s\", help=\"model size type: tiny, large.\")\n",
    "    parser.add_argument(\"--fp16\", type=str, help=\"half precision support\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    path = args.p\n",
    "    num_frames = args.f\n",
    "    fp16 = True if args.fp16 else False\n",
    "\n",
    "    net = 'genconvit'\n",
    "    ed_weight = 'genconvit_ed_inference'\n",
    "    vae_weight = 'genconvit_vae_inference'\n",
    "\n",
    "    if args.s:\n",
    "        if args.s in ['tiny', 'large']:\n",
    "            config[\"model\"][\"backbone\"] = f\"convnext_{args.s}\"\n",
    "            config[\"model\"][\"embedder\"] = f\"swin_{args.s}_patch4_window7_224\"\n",
    "            config[\"model\"][\"type\"] = args.s\n",
    "\n",
    "    return path, num_frames, net, fp16, ed_weight, vae_weight\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 파라미터 로드\n",
    "    path, num_frames, net, fp16, ed_weight, vae_weight = gen_parser()\n",
    "\n",
    "    # 모델 로드\n",
    "    print(\"Loading model...\")\n",
    "    model = load_genconvit(config, net, ed_weight, vae_weight, fp16)\n",
    "    print(f\"✓ Loaded {net} network\\n\")\n",
    "\n",
    "    # 파일 수집\n",
    "    root_dir = path\n",
    "    all_files = get_files_paths(root_dir, exs=['png', 'jpg', 'jpeg', 'mp4'])\n",
    "    print(f\"✓ Found {len(all_files)} files\")\n",
    "\n",
    "    # Setup multiprocessing\n",
    "    num_workers = min(max(1, multiprocessing.cpu_count() - 1), 8)\n",
    "    print(f\"✓ Using {num_workers} worker processes for preprocessing\\n\")\n",
    "    \n",
    "    # Prepare worker arguments\n",
    "    worker_args = [(file_path, num_frames) for file_path in all_files]\n",
    "\n",
    "    results = []\n",
    "    all_frame_results = []\n",
    "    \n",
    "    # Statistics\n",
    "    sequence_override_count = 0\n",
    "    frame_ratio_override_count = 0\n",
    "    temporal_override_count = 0\n",
    "    secondary_check_count = 0\n",
    "    \n",
    "    print(\"Start Evaluating with Postprocessing...\\n\")\n",
    "    \n",
    "    # Parallel preprocessing (CPU)\n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        with tqdm(total=len(all_files), desc=\"Processing files\") as pbar:\n",
    "            for result in pool.imap_unordered(process_single_file_cpu, worker_args):\n",
    "                filename, face_crops, raw_frames, laplacian_vars, is_video_file, error = result\n",
    "                \n",
    "                # Check for errors\n",
    "                if error:\n",
    "                    print(f\"Error processing {filename}: {error}\")\n",
    "                    results.append({\n",
    "                        \"name\": filename,\n",
    "                        \"pred\": 0,\n",
    "                        \"pred_proba\": [0.5, 0.5]\n",
    "                    })\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # No face detected\n",
    "                if face_crops is None:\n",
    "                    results.append({\n",
    "                        \"name\": filename,\n",
    "                        \"pred\": 0,\n",
    "                        \"pred_proba\": [0.5, 0.5]\n",
    "                    })\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # ===== GPU INFERENCE =====\n",
    "                df = preprocess_frame(face_crops)\n",
    "                if fp16 and df.shape[0] > 0:\n",
    "                    df = df.half()\n",
    "                \n",
    "                if df.shape[0] > 0:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(df)\n",
    "                        probs = torch.softmax(outputs, dim=1)\n",
    "                        \n",
    "                        real_probas = probs[:, 0].cpu().numpy()\n",
    "                        fake_probas = probs[:, 1].cpu().numpy()\n",
    "                        \n",
    "                        # Store per-frame results\n",
    "                        for frame_idx, (real_p, fake_p) in enumerate(zip(real_probas, fake_probas)):\n",
    "                            pred = 1 if fake_p >= real_p else 0\n",
    "                            all_frame_results.append({\n",
    "                                'filename': filename,\n",
    "                                'frame_idx': frame_idx,\n",
    "                                'real_proba': float(real_p),\n",
    "                                'fake_proba': float(fake_p),\n",
    "                                'pred': pred\n",
    "                            })\n",
    "                    \n",
    "                    # Calculate average\n",
    "                    avg_real = np.mean(real_probas)\n",
    "                    avg_fake = np.mean(fake_probas)\n",
    "                    predicted_class = 1 if avg_fake >= avg_real else 0\n",
    "                    \n",
    "                    # ===== POSTPROCESSING =====\n",
    "                    \n",
    "                    if is_video_file:\n",
    "                        # 1. Sequence analysis\n",
    "                        if df.shape[0] > 5:\n",
    "                            window_size = 5\n",
    "                            moving_avg = np.convolve(fake_probas, np.ones(window_size)/window_size, mode=\"valid\")\n",
    "                            \n",
    "                            high_fake_ratio = np.mean(moving_avg > 0.45)\n",
    "                            mid_fake_ratio = np.mean(moving_avg > 0.35)\n",
    "                            max_moving_avg = np.max(moving_avg)\n",
    "                            avg_fake_prob = np.mean(fake_probas)\n",
    "                            \n",
    "                            if (high_fake_ratio > 0.12 or mid_fake_ratio > 0.30 or \n",
    "                                max_moving_avg > 0.55 or avg_fake_prob > 0.30):\n",
    "                                if predicted_class == 0:\n",
    "                                    sequence_override_count += 1\n",
    "                                predicted_class = 1\n",
    "                                # print(f\"[SEQ-OVERRIDE] {filename}\")\n",
    "                        \n",
    "                        # 2. Frame ratio check\n",
    "                        fake_frame_count = np.sum(fake_probas > 0.5)\n",
    "                        fake_frame_ratio = fake_frame_count / len(fake_probas)\n",
    "                        \n",
    "                        if fake_frame_ratio > 0.25:\n",
    "                            if predicted_class == 0:\n",
    "                                frame_ratio_override_count += 1\n",
    "                            predicted_class = 1\n",
    "                            # print(f\"[FRAME-RATIO-OVERRIDE] {filename}: {fake_frame_ratio:.2%}\")\n",
    "                        \n",
    "                        # 3. Temporal analysis\n",
    "                        if len(raw_frames) >= 5 and laplacian_vars:\n",
    "                            temporal_var = calculate_temporal_variance(raw_frames)\n",
    "                            detail_stability = calculate_detail_stability(laplacian_vars)\n",
    "                            avg_sharpness = np.mean(laplacian_vars)\n",
    "                            \n",
    "                            is_fake_temporal, temp_confidence, video_type = classify_video_type(\n",
    "                                temporal_var, detail_stability, avg_sharpness\n",
    "                            )\n",
    "                            \n",
    "                            if is_fake_temporal is not None and is_fake_temporal:\n",
    "                                if predicted_class == 0:\n",
    "                                    temporal_override_count += 1\n",
    "                                predicted_class = 1\n",
    "                                # print(f\"[TEMPORAL-OVERRIDE] {filename}: {video_type}\")\n",
    "                    \n",
    "                    else:\n",
    "                        # Image postprocessing\n",
    "                        if laplacian_vars:\n",
    "                            lap_var = laplacian_vars[0]\n",
    "                            SHARPNESS_THRESHOLD = 180.0\n",
    "                            \n",
    "                            if lap_var > SHARPNESS_THRESHOLD and predicted_class == 0:\n",
    "                                suspicion_score = perform_secondary_checks(face_crops[0], lap_var)\n",
    "                                SUSPICION_THRESHOLD = 0.60\n",
    "                                \n",
    "                                if suspicion_score > SUSPICION_THRESHOLD:\n",
    "                                    predicted_class = 1\n",
    "                                    secondary_check_count += 1\n",
    "                                    # print(f\"[OVERRIDE] {filename}: Sharp but suspicious\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"name\": filename,\n",
    "                        \"pred\": predicted_class,\n",
    "                        \"pred_proba\": [float(avg_real), float(avg_fake)]\n",
    "                    })\n",
    "                else:\n",
    "                    results.append({\n",
    "                        \"name\": filename,\n",
    "                        \"pred\": 0,\n",
    "                        \"pred_proba\": [0.5, 0.5]\n",
    "                    })\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "    # 결과 저장\n",
    "    print(\"\\n✓ Processing complete!\\n\")\n",
    "    \n",
    "    # 1. 최종 제출용 CSV\n",
    "    save_results_to_csv(results, \"submission.csv\", for_submit=True)\n",
    "    print(f\"✓ Saved submission to submission.csv\")\n",
    "    \n",
    "    # # 2. 프레임별 확률 CSV\n",
    "    # if all_frame_results:\n",
    "    #     save_frame_probabilities_to_csv(all_frame_results, \"frame_probabilities.csv\")\n",
    "    #     print(f\"✓ Saved frame probabilities to frame_probabilities.csv\")\n",
    "    \n",
    "    # 통계 출력\n",
    "    print(f\"\\n=== Detection Statistics ===\")\n",
    "    print(f\"Sequence analysis overrides: {sequence_override_count}\")\n",
    "    print(f\"Frame ratio overrides: {frame_ratio_override_count}\")\n",
    "    print(f\"Temporal analysis overrides: {temporal_override_count}\")\n",
    "    print(f\"Secondary check overrides: {secondary_check_count}\")\n",
    "    \n",
    "    num_fake = sum(1 for r in results if r['pred'] == 1)\n",
    "    num_real = len(results) - num_fake\n",
    "    \n",
    "    print(f\"\\n=== Prediction Summary ===\")\n",
    "    print(f\"Total files: {len(results)}\")\n",
    "    print(f\"  Real: {num_real} ({num_real/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Fake: {num_fake} ({num_fake/len(results)*100:.1f}%)\")\n",
    "    \n",
    "    if all_frame_results:\n",
    "        num_fake_frames = sum(1 for r in all_frame_results if r['pred'] == 1)\n",
    "        print(f\"\\nTotal frames: {len(all_frame_results)}\")\n",
    "        print(f\"  Fake frames: {num_fake_frames} ({num_fake_frames/len(all_frame_results)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
